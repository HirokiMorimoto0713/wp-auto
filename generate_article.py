import os
import openai
import json
import re
import csv
import requests
import yaml
import statistics as st
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# .env ã‹ã‚‰ APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# æ–°ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®å®šæ•°ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
NEW_KEYWORDS_CSV = "keywords.csv"  # æ–°ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçµ±åˆå½¢å¼ï¼‰
INDEX_FILE = "current_index.txt"

def get_next_keyword_group() -> dict:
    """
    æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¬¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
    Båˆ—ãŒåŒã˜å€¤ã®è¡Œã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¿”ã™
    """
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
    idx = 0
    if os.path.exists(INDEX_FILE):
        with open(INDEX_FILE) as f:
            idx = int(f.read().strip() or 0)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    try:
        # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ãŸã¯Documentsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        current_dir = os.getcwd()
        print(f"ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {current_dir}")
        
        csv_paths = [
            NEW_KEYWORDS_CSV,  # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç›´æ¥æŒ‡å®šï¼‰
            os.path.join(current_dir, NEW_KEYWORDS_CSV),  # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰
            os.path.expanduser(f"~/Documents/{NEW_KEYWORDS_CSV}"),  # Documentsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            os.path.expanduser(f"~/{NEW_KEYWORDS_CSV}")  # ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        ]
        
        print(f"æ¤œç´¢ãƒ‘ã‚¹: {csv_paths}")
        
        csv_path = None
        for path in csv_paths:
            print(f"ãƒã‚§ãƒƒã‚¯ä¸­: {path} -> å­˜åœ¨: {os.path.exists(path)}")
            if os.path.exists(path):
                csv_path = path
                break
                
        if not csv_path:
            raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_paths}")
            
        print(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {csv_path}")
        df = pd.read_csv(csv_path, header=None, names=['keyword', 'group_id', 'main_category', 'sub_category'])
        
        # ã‚°ãƒ«ãƒ¼ãƒ—IDã§ã‚½ãƒ¼ãƒˆ
        df = df.sort_values('group_id')
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚°ãƒ«ãƒ¼ãƒ—IDã‚’å–å¾—
        unique_groups = df['group_id'].unique()
        unique_groups = sorted([g for g in unique_groups if pd.notna(g)])
        
        if not unique_groups:
            raise ValueError("æœ‰åŠ¹ãªã‚°ãƒ«ãƒ¼ãƒ—IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ç¾åœ¨ã®ã‚°ãƒ«ãƒ¼ãƒ—IDå–å¾—
        current_group_id = unique_groups[idx % len(unique_groups)]
        
        # è©²å½“ã‚°ãƒ«ãƒ¼ãƒ—ã®å…¨è¡Œã‚’å–å¾—
        group_data = df[df['group_id'] == current_group_id]
        
        # æ¬¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        with open(INDEX_FILE, "w") as f:
            f.write(str((idx + 1) % len(unique_groups)))
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã§è¿”ã™
        keywords = group_data['keyword'].tolist()
        main_category = group_data['main_category'].iloc[0] if pd.notna(group_data['main_category'].iloc[0]) else ""
        sub_category = group_data['sub_category'].iloc[0] if pd.notna(group_data['sub_category'].iloc[0]) else ""
        
        return {
            'group_id': current_group_id,
            'keywords': keywords,
            'main_category': main_category,
            'sub_category': sub_category,
            'primary_keyword': keywords[0] if keywords else ""
        }
        
    except Exception as e:
        print(f"âš ï¸ æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—§ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨
        return {
            'group_id': 1,
            'keywords': [get_next_keyword_legacy()],
            'main_category': "",
            'sub_category': "",
            'primary_keyword': get_next_keyword_legacy()
        }

def get_next_keyword_legacy(col: int = 0) -> str:
    """
    æ—§ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    """
    idx = 0
    if os.path.exists(INDEX_FILE):
        with open(INDEX_FILE) as f:
            idx = int(f.read().strip() or 0)
    
    # æ—§keywords.csvãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    old_keywords_csv = "keywords.csv"
    if not os.path.exists(old_keywords_csv):
        return "ChatGPT ä½¿ã„æ–¹"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    
    with open(old_keywords_csv, encoding="utf-8") as f:
        reader = csv.reader(f)
        next(reader)  # 1è¡Œã‚¹ã‚­ãƒƒãƒ—
        keywords = [row[col] for row in reader if len(row) > col]
    
    if not keywords:
        return "ChatGPT ä½¿ã„æ–¹"
    
    keyword = keywords[idx % len(keywords)]
    with open(INDEX_FILE, "w") as f:
        f.write(str((idx + 1) % len(keywords)))
    return keyword

def generate_integrated_article_from_keywords(keyword_group: dict, style_features: dict = None, num_sections: int = 5) -> dict:
    """
    è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸSEOåŠ¹æœçš„ãªè¨˜äº‹ã‚’ç”Ÿæˆ
    """
    keywords = keyword_group['keywords']
    primary_keyword = keyword_group['primary_keyword']
    
    print(f"ğŸ¯ çµ±åˆè¨˜äº‹ç”Ÿæˆé–‹å§‹:")
    print(f"   ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {primary_keyword}")
    print(f"   é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords[1:]) if len(keywords) > 1 else 'ãªã—'}")
    
    # çµ±åˆçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    keywords_text = "ã€".join(keywords)
    integrated_prompt = f"""
{primary_keyword}ã‚’ä¸­å¿ƒã¨ã—ãŸåŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## å«ã‚ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆSEOæœ€é©åŒ–ï¼‰
{chr(10).join([f"- {kw}" for kw in keywords])}

## è¨˜äº‹ã®æ–¹é‡
- ä¸Šè¨˜ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«çµ±åˆã—ãŸå†…å®¹
- SEOåŠ¹æœçš„ãªæ§‹æˆã§æ¤œç´¢ãƒ‹ãƒ¼ã‚ºã«å¯¾å¿œ
- åˆå¿ƒè€…ã‹ã‚‰ä¸Šç´šè€…ã¾ã§å¹…åºƒã„ãƒ¬ãƒ™ãƒ«ã«å¯¾å¿œ
- å®Ÿè·µçš„ã§å…·ä½“çš„ãªã‚¬ã‚¤ãƒ‰
- å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢æ„å›³ã‚’æº€ãŸã™å†…å®¹ã‚’å«ã‚€
"""

    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä½¿ç”¨åˆ¤å®š
    if style_features and not style_features.get('error'):
        print("ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã§è¨˜äº‹ç”Ÿæˆ")
        article = generate_keyword_article_with_style_integrated(integrated_prompt, keywords, style_features, num_sections)
    else:
        print("ğŸ“ æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ã§è¨˜äº‹ç”Ÿæˆ")
        article = generate_article_html_integrated(integrated_prompt, keywords, num_sections)
    
    # ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã«åŸºã¥ã„ã¦æœ€é©ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
    optimized_title = generate_optimized_title_from_content(article['content'], keywords, primary_keyword)
    article['title'] = optimized_title
    
    # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’è¿½åŠ 
    article['main_category'] = keyword_group['main_category']
    article['sub_category'] = keyword_group['sub_category']
    article['keywords_used'] = keywords
    article['primary_keyword'] = primary_keyword
    article['integrated_article'] = True
    
    return article

def generate_optimized_title_from_content(content: str, keywords: list, primary_keyword: str) -> str:
    """
    å®Œæˆã—ãŸè¨˜äº‹å†…å®¹ã«åŸºã¥ã„ã¦æœ€é©ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
    """
    keywords_text = "ã€".join(keywords)
    
    title_prompt = f"""
ã‚ãªãŸã¯SEOã¨èª­è€…å¿ƒç†ã«é•·ã‘ãŸãƒ–ãƒ­ã‚°ç·¨é›†è€…ã§ã™ã€‚

ä»¥ä¸‹ã®è¨˜äº‹å†…å®¹ã¨å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åŸºã«ã€æœ€é©ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
ãƒ¡ã‚¤ãƒ³: {primary_keyword}
é–¢é€£: {', '.join(keywords[1:]) if len(keywords) > 1 else 'ãªã—'}

## è¨˜äº‹å†…å®¹ã®è¦ç´„
{content[:800]}...

## ã‚¿ã‚¤ãƒˆãƒ«ç”ŸæˆæŒ‡é‡
- æ—¢å­˜ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‚è€ƒã«é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«
- ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¿…ãšå«ã‚ã‚‹
- é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è‡ªç„¶ã«å«ã‚ã‚‹ï¼ˆå¯èƒ½ãªé™ã‚Šï¼‰
- SEOåŠ¹æœçš„ã§ã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã‚„ã™ã„
- è¨˜äº‹ã®å®Ÿéš›ã®å†…å®¹ã‚’æ­£ç¢ºã«è¡¨ç¾
- åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¾

## å‚è€ƒã‚¿ã‚¤ãƒˆãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆæŸ”ã‚‰ã‹ãã‚­ãƒ£ãƒƒãƒãƒ¼ãªæ–‡ä½“ï¼‰
- "è¶…ç°¡å˜ï¼ã€‡ã€‡ã‚’5åˆ†ã§è¦šãˆã‚‹æ–¹æ³•"
- "åˆå¿ƒè€…ã•ã‚“ã§ã‚‚å®‰å¿ƒã€‚ã€‡ã€‡ã®å„ªã—ã„å§‹ã‚æ–¹"
- "ã€‡ã€‡ã§æ¯æ—¥ãŒã¡ã‚‡ã£ã¨æ¥½ã—ããªã£ãŸè©±"
- "çŸ¥ã‚‰ãªãã‚ƒæï¼ã€‡ã€‡ã®ä¾¿åˆ©ãªä½¿ã„æ–¹"
- "ä»Šã™ãè©¦ã—ãŸã„ã€‡ã€‡ã®ã‚³ãƒ„7é¸"
- "ã€‡ã€‡åˆå¿ƒè€…ã®ç§ãŒå®Ÿéš›ã«ã‚„ã£ã¦ã¿ãŸçµæœ"
- "æ„å¤–ã¨ç°¡å˜ã ã£ãŸã€‡ã€‡ã®æ´»ç”¨è¡“"

JSONã§{{"title": "..."}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
    
    try:
        resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": title_prompt},
                {"role": "user", "content": f"ä¸Šè¨˜ã®è¨˜äº‹å†…å®¹ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã€æœ€é©ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"}
            ],
            temperature=0.8,
            max_tokens=200,
            response_format={"type": "json_object"}
        )
        return json.loads(resp.choices[0].message.content)["title"]
    except Exception as e:
        print(f"âš ï¸ ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥æ–¹å¼
        return generate_title_variants(f"{primary_keyword}ã«ã¤ã„ã¦", n=1)[0]

# æ—¢å­˜ã® get_next_keyword é–¢æ•°ã‚’å‰Šé™¤ã—ã¦æ–°ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾å¿œ
def get_next_keyword(col: int = 0) -> str:
    """
    å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°ï¼ˆéæ¨å¥¨ï¼‰
    æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ get_next_keyword_group() ã‚’ä½¿ç”¨
    """
    keyword_group = get_next_keyword_group()
    return keyword_group['primary_keyword']

def generate_title_variants(prompt: str, n: int = 5) -> list[str]:
    """
    ãƒ†ãƒ¼ãƒ(prompt)ã«åˆã†"ã‚¤ã‚±ã¦ã‚‹"æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’nå€‹ç”Ÿæˆ
    """
    style_examples = [
        "è¶…ç°¡å˜ï¼ã€‡ã€‡ã‚’5åˆ†ã§è¦šãˆã‚‹æ–¹æ³•",
        "åˆå¿ƒè€…ã•ã‚“ã§ã‚‚å®‰å¿ƒã€‚ã€‡ã€‡ã®å„ªã—ã„å§‹ã‚æ–¹",
        "ã€‡ã€‡ã§æ¯æ—¥ãŒã¡ã‚‡ã£ã¨æ¥½ã—ããªã£ãŸè©±",
        "çŸ¥ã‚‰ãªãã‚ƒæï¼ã€‡ã€‡ã®ä¾¿åˆ©ãªä½¿ã„æ–¹",
        "ä»Šã™ãè©¦ã—ãŸã„ã€‡ã€‡ã®ã‚³ãƒ„7é¸",
        "ã€‡ã€‡åˆå¿ƒè€…ã®ç§ãŒå®Ÿéš›ã«ã‚„ã£ã¦ã¿ãŸçµæœ",
        "æ„å¤–ã¨ç°¡å˜ã ã£ãŸã€‡ã€‡ã®æ´»ç”¨è¡“"
    ]

    examples_text = "\n".join([f"- {ex}" for ex in style_examples])

    system_prompt = (
        "ã‚ãªãŸã¯SEOã¨èª­è€…å¿ƒç†ã«é•·ã‘ãŸãƒ–ãƒ­ã‚°ç·¨é›†è€…ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã®**æŸ”ã‚‰ã‹ãã‚­ãƒ£ãƒƒãƒãƒ¼ãªæ–‡ä½“**ã‚’å‚è€ƒã«ã€\n"
        "ä¸ãˆã‚‰ã‚ŒãŸãƒ†ãƒ¼ãƒã«å¯¾ã™ã‚‹è¦ªã—ã¿ã‚„ã™ãé­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’è¤‡æ•°ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»è¦ªã—ã¿ã‚„ã™ãã€èª­ã¿ã‚„ã™ã„è¡¨ç¾ã‚’å¿ƒãŒã‘ã‚‹\n"
        "ãƒ»åˆå¿ƒè€…ã§ã‚‚å®‰å¿ƒã§ãã‚‹ã‚ˆã†ãªå„ªã—ã„èªèª¿\n"
        "ãƒ»èª­è€…ã®èˆˆå‘³ã‚’å¼•ãå…·ä½“çš„ãªãƒ¡ãƒªãƒƒãƒˆè¡¨ç¾\n"
        "ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã‚’ãã®ã¾ã¾ä½¿ã†ã“ã¨ã¯è¨±ã—ã¾ã›ã‚“\n"
        "ã‚¿ã‚¤ãƒˆãƒ«ä¾‹:\n" + examples_text + "\n"
        "å‡ºåŠ›ã¯JSONå½¢å¼ã§ â†’ {\"titles\": [\"â€¦\", \"â€¦\", â€¦]}"
    )

    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": prompt}
        ],
        temperature=0.95,
        max_tokens=500,
        response_format={"type": "json_object"}
    )
    return json.loads(resp.choices[0].message.content)["titles"]

def generate_article_html(prompt: str, num_sections: int = 5) -> dict:
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title = generate_title_variants(prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_msg = (
    "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
        "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
        "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
        "ãƒ»å…±æ„Ÿï¼šæƒ…å ±æç¤º = 3:7ã€œ4:6 ç¨‹åº¦\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
        "ãƒ»æœ¬æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã›ãšã€ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã«ã—ã¦ãã ã•ã„\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]


    # ç« ã”ã¨ç”Ÿæˆ
    sections = []
    for i in range(1, num_sections + 1):
        # è¡¨ã®ä½¿ç”¨åˆ¶é™ï¼ˆ1è¨˜äº‹ã‚ãŸã‚Š2ã¤ã¾ã§ï¼‰
        can_use_table = i <= 2  # ç¬¬1ç« ã¨ç¬¬2ç« ã®ã¿è¡¨ã‚’ä½¿ç”¨å¯èƒ½
        
        section_msg = (
            "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"ã“ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
            "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
            "ğŸ“ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n"
            "- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n"
            "- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\n"
            "ğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n"
            "- ç®‡æ¡æ›¸ãï¼ˆ<ul><li>ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n"
            "- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ<ol><li>ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n"
            "- å°è¦‹å‡ºã—ï¼ˆ<h3>ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n"
            "- å¤ªå­—ï¼ˆ<strong>ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n"
            "- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n"
            "- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\n"
            "ğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n"
            "- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n"
            "- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n"
            "- ã€Œã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§æ•™ãˆã¦ã€ã¨ä¾é ¼ã™ã‚‹ã¨è©³ã—ãæ•™ãˆã¦ãã‚Œã¾ã™ã€\n"
            "- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\n"
            f"{'ğŸ“Š è¡¨ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š' if can_use_table else 'ğŸ“„ ã“ã®ç« ã§ã¯è¡¨ã¯ä½¿ç”¨ã›ãšã€æ–‡ç« ã§ã®èª¬æ˜ã‚’ä¸­å¿ƒã«ã—ã¦ãã ã•ã„ï¼š'}\n"
            f"{'- ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®3åˆ—æ§‹æˆ' if can_use_table else '- åˆ†ã‹ã‚Šã‚„ã™ã„ç®‡æ¡æ›¸ãã§ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†'}\n"
            f"{'- ã€Œã‚¹ãƒ†ãƒƒãƒ—ã€ã€Œå†…å®¹ã€ã€Œãƒã‚¤ãƒ³ãƒˆã€ã®æ‰‹é †è¡¨' if can_use_table else '- æ®µéšçš„ãªèª¬æ˜ã§èª­è€…ã‚’ã‚µãƒãƒ¼ãƒˆ'}\n\n"
            "ğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n"
            "- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n"
            "- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n"
            f"{'- è¨˜äº‹å…¨ä½“ã§è¡¨ã¯2ã¤ã¾ã§ãªã®ã§ã€ã“ã®ç« ã§ä½¿ç”¨ã™ã‚‹å ´åˆã¯åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„' if can_use_table else '- ã“ã®ç« ã§ã¯è¡¨ã‚’ä½¿ç”¨ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®èª¬æ˜ã«é›†ä¸­ã—ã¦ãã ã•ã„'}\n\n"
            "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    conclusion_section = generate_conclusion_section(prompt, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    return {
        "title": title,
        "content": content
    }


def generate_image_prompt(article_body: str) -> str:
    """
    è¨˜äº‹æœ¬æ–‡HTMLã‹ã‚‰è‹±èªã®ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    """
    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": (
                    "ã‚ãªãŸã¯ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚"
                    "ä»¥ä¸‹ã®HTMLå½¢å¼ã®è¨˜äº‹ã«åˆã£ãŸã€éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒŸãƒ‹ãƒãƒ«ãªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®"
                    "è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’1æ–‡ã ã‘ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\n"
                    "è¦ä»¶ï¼š\n"
                    "- flat design, minimalist style ã‚’å¿…ãšå«ã‚ã‚‹\n"
                    "- è¤‡é›‘ãªè¦ç´ ã¯é¿ã‘ã€2-3å€‹ã®åŸºæœ¬çš„ãªè¦ç´ ã®ã¿\n"
                    "- ãƒ‘ã‚¹ãƒ†ãƒ«ã‚«ãƒ©ãƒ¼ã¾ãŸã¯ç™½èƒŒæ™¯ã‚’ä½¿ç”¨\n"
                    "- ã‚¢ã‚¤ã‚³ãƒ³ã‚„ã‚¤ãƒ©ã‚¹ãƒˆé¢¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚¶ã‚¤ãƒ³\n"
                    "- æ–‡å­—ã‚„ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„\n"
                    "- ä¾‹: 'Simple flat design icon of a lightbulb on white background, minimalist style, pastel colors'"
                )
            },
            {"role": "user", "content": article_body}
        ],
        temperature=0.5,
        max_tokens=200
    )
    return resp.choices[0].message.content.strip()


def generate_image_url(image_prompt: str) -> str:
    """
    DALLÂ·E 3 ã«ç”»åƒç”Ÿæˆã‚’é ¼ã¿ã€URLã‚’è¿”ã™
    """
    response = openai.images.generate(
        model="dall-e-3",
        prompt=image_prompt,
        size="1792x1024",
        n=1
    )
    image_url = response.data[0].url
    return image_url


def generate_meta_description(prompt: str, content: str) -> str:
    """
    è¨˜äº‹ã®meta descriptionã‚’ç”Ÿæˆï¼ˆ150-160æ–‡å­—ç¨‹åº¦ï¼‰
    """
    desc_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®meta descriptionï¼ˆæ¤œç´¢çµæœã«è¡¨ç¤ºã•ã‚Œã‚‹èª¬æ˜æ–‡ï¼‰ã‚’æ—¥æœ¬èªã§150æ–‡å­—ä»¥å†…ã§æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã‚ˆã†ãªé­…åŠ›çš„ãªæ–‡ç« \n"
        "ãƒ»è¨˜äº‹ã®è¦ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹\n"
        "ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«å«ã‚ã‚‹\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§çµ±ä¸€\n"
        "JSONã§{\"description\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    desc_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": desc_msg},
            {"role": "user", "content": f"ãƒ†ãƒ¼ãƒ: {prompt}\nè¨˜äº‹å†…å®¹: {content[:500]}..."}
        ],
        temperature=0.5,
        max_tokens=300,
        response_format={"type": "json_object"}
    )
    return json.loads(desc_resp.choices[0].message.content)["description"]


def generate_seo_tags(prompt: str, content: str) -> list[str]:
    """
    è¨˜äº‹ã®SEOåŠ¹æœçš„ãªWordPressã‚¿ã‚°ã‚’3ã¤ç”Ÿæˆ
    """
    tags_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€å®¶ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã«æœ€é©ãªWordPressã‚¿ã‚°ã‚’3ã¤é¸ã‚“ã§ãã ã•ã„ã€‚\n"
        "ãƒ»SEOåŠ¹æœãŒé«˜ãã€æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n"
        "ãƒ»è¨˜äº‹å†…å®¹ã¨é–¢é€£æ€§ãŒé«˜ã„ã‚‚ã®\n"
        "ãƒ»ä¸€èˆ¬çš„ã™ããšã€å…·ä½“çš„ã™ããªã„é©åº¦ãªç²’åº¦\n"
        "ãƒ»æ—¥æœ¬èªã§ã€å„ã‚¿ã‚°ã¯2-4æ–‡å­—ç¨‹åº¦\n"
        "ãƒ»ä¾‹: 'AI', 'ChatGPT', 'ç„¡æ–™ãƒ„ãƒ¼ãƒ«', 'åˆå¿ƒè€…å‘ã‘' ãªã©\n"
        "JSONã§{\"tags\": [\"ã‚¿ã‚°1\", \"ã‚¿ã‚°2\", \"ã‚¿ã‚°3\"]}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    tags_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": tags_msg},
            {"role": "user", "content": f"ãƒ†ãƒ¼ãƒ: {prompt}\nè¨˜äº‹å†…å®¹: {content[:300]}..."}
        ],
        temperature=0.5,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    return json.loads(tags_resp.choices[0].message.content)["tags"]


def generate_seo_slug(prompt: str, title: str) -> str:
    """
    è¨˜äº‹ã®SEOåŠ¹æœçš„ãªã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚¹ãƒ©ãƒƒã‚°ã‚’ç”Ÿæˆï¼ˆ3-5èªç¨‹åº¦ï¼‰
    """
    slug_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€å®¶ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®WordPressã‚¹ãƒ©ãƒƒã‚°ï¼ˆURLï¼‰ã‚’è‹±èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»3-5èªç¨‹åº¦ã®çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚º\n"
        "ãƒ»ãƒã‚¤ãƒ•ãƒ³ã§åŒºåˆ‡ã‚‹ï¼ˆä¾‹: chatgpt-free-guideï¼‰\n"
        "ãƒ»SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€\n"
        "ãƒ»è¨˜äº‹å†…å®¹ã‚’è¡¨ã™åˆ†ã‹ã‚Šã‚„ã™ã„è‹±èª\n"
        "ãƒ»å°æ–‡å­—ã®ã¿ä½¿ç”¨\n"
        "ãƒ»æ•°å­—ã¯ä½¿ç”¨å¯èƒ½\n"
        "JSONã§{\"slug\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    slug_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": slug_msg},
            {"role": "user", "content": f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {prompt}\nã‚¿ã‚¤ãƒˆãƒ«: {title}"}
        ],
        temperature=0.3,
        max_tokens=150,
        response_format={"type": "json_object"}
    )
    return json.loads(slug_resp.choices[0].message.content)["slug"]


def extract_article_structure(url_or_content: str, content_type: str = "url") -> dict:
    """
    å‚è€ƒè¨˜äº‹ã‹ã‚‰HTMLã¾ãŸã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®æ§‹é€ ã‚’æŠ½å‡º
    content_type: "url", "html", "markdown"
    """
    if content_type == "url":
        # URLã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
        try:
            response = requests.get(url_or_content, timeout=30)
            response.raise_for_status()
            html_content = response.text
        except Exception as e:
            print(f"URLå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
            
        # HTMLã‹ã‚‰æ§‹é€ æŠ½å‡º
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
        for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            tag.decompose()
            
        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
        title = ""
        if soup.find('h1'):
            title = soup.find('h1').get_text().strip()
        elif soup.find('title'):
            title = soup.find('title').get_text().strip()
            
        # è¦‹å‡ºã—ã¨å†…å®¹æŠ½å‡º
        sections = []
        for i, heading in enumerate(soup.find_all(['h2', 'h3', 'h4'])):
            heading_text = heading.get_text().strip()
            
            # è¦‹å‡ºã—å¾Œã®å†…å®¹ã‚’å–å¾—
            content_parts = []
            current = heading.next_sibling
            while current and current.name not in ['h1', 'h2', 'h3', 'h4']:
                if hasattr(current, 'get_text'):
                    text = current.get_text().strip()
                    if text and len(text) > 10:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                        content_parts.append(text)
                current = current.next_sibling
                if len(content_parts) > 3:  # é•·ã™ãã‚‹å ´åˆã¯åˆ¶é™
                    break
                    
            sections.append({
                "heading": heading_text,
                "content": " ".join(content_parts)[:200] + "..." if content_parts else ""
            })
            
            if len(sections) >= 5:  # æœ€å¤§5ã¤ã¾ã§
                break
        
        return {
            "title": title,
            "sections": sections,
            "total_sections": len(sections)
        }
        
    elif content_type == "html":
        # HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ç›´æ¥æŠ½å‡º
        soup = BeautifulSoup(url_or_content, 'html.parser')
        # ä¸Šè¨˜ã¨åŒã˜å‡¦ç†...
        
    elif content_type == "markdown":
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‹ã‚‰æ§‹é€ æŠ½å‡º
        lines = url_or_content.split('\n')
        sections = []
        current_section = None
        
        for line in lines:
            if line.startswith('#'):
                if current_section:
                    sections.append(current_section)
                    
                level = len(line) - len(line.lstrip('#'))
                heading = line.lstrip('# ').strip()
                current_section = {
                    "heading": heading,
                    "content": "",
                    "level": level
                }
            elif current_section and line.strip():
                current_section["content"] += line + " "
                
        if current_section:
            sections.append(current_section)
            
        # h2ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿æŠ½å‡º
        h2_sections = [s for s in sections if s.get("level", 0) == 2][:5]
        
        return {
            "title": next((s["heading"] for s in sections if s.get("level", 0) == 1), ""),
            "sections": h2_sections,
            "total_sections": len(h2_sections)
        }
    
    return {"error": "ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—"}

def generate_article_from_reference(prompt: str, reference_structure: dict, num_sections: int = 5) -> dict:
    """
    å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã«åŸºã¥ã„ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in reference_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®æ§‹é€ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿
    structure_text = f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {reference_structure.get('title', '')}\n\n"
    structure_text += "å‚è€ƒè¨˜äº‹ã®è¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(reference_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:100]}...\n"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    title_prompt = f"""
ä»¥ä¸‹ã®å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚’å‚è€ƒã«ã€ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{structure_text}

å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã®ã‚ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    
    title = generate_title_variants(title_prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    lead_msg = (
        "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "ä»¥ä¸‹ã®å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n\n"
        f"{structure_text}\n\n"
        "ãƒ»3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
        "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # ç« ã”ã¨ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’æ´»ç”¨ï¼‰
    sections = []
    ref_sections = reference_structure.get('sections', [])
    
    for i in range(1, num_sections + 1):
        # å‚è€ƒè¨˜äº‹ã®å¯¾å¿œã™ã‚‹ç« ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹
        ref_section = ref_sections[i-1] if i-1 < len(ref_sections) else None
        
        section_msg = (
            "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        )
        
        if ref_section:
            section_msg += f"å‚è€ƒã¨ãªã‚‹ç« ã®è¦‹å‡ºã—: ã€Œ{ref_section['heading']}ã€\n"
            if ref_section.get('content'):
                section_msg += f"å‚è€ƒç« ã®å†…å®¹æ¦‚è¦: {ref_section['content'][:150]}...\n"
            section_msg += "ä¸Šè¨˜ã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã®ã‚ã‚‹å†…å®¹ã§ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
            
        section_msg += (
            "ãƒ»2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
            "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    conclusion_section = generate_conclusion_section(prompt, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    return {
        "title": title,
        "content": content,
        "reference_used": True
    }

def extract_multiple_article_structures(sources: list, content_types: list = None) -> dict:
    """
    è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‹ã‚‰æ§‹é€ ã‚’æŠ½å‡ºãƒ»çµ±åˆ
    sources: URLã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    content_types: å„ã‚½ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ ["url", "file", "markdown", "html"]
    """
    if content_types is None:
        # è‡ªå‹•åˆ¤å®š
        content_types = []
        for source in sources:
            if source.startswith(('http://', 'https://')):
                content_types.append('url')
            elif source.endswith('.md'):
                content_types.append('markdown')
            else:
                content_types.append('html')
    
    all_structures = []
    successful_sources = []
    
    for i, (source, content_type) in enumerate(zip(sources, content_types)):
        print(f"ğŸ“– å‚è€ƒè¨˜äº‹ {i+1}/{len(sources)} ã‚’å‡¦ç†ä¸­: {source}")
        
        try:
            if content_type == 'url':
                structure = extract_article_structure(source, "url")
            elif content_type in ['markdown', 'html']:
                if content_type == 'markdown':
                    with open(source, 'r', encoding='utf-8') as f:
                        content = f.read()
                    structure = extract_article_structure(content, "markdown")
                else:
                    with open(source, 'r', encoding='utf-8') as f:
                        content = f.read()
                    structure = extract_article_structure(content, "html")
            
            if "error" not in structure:
                all_structures.append({
                    'source': source,
                    'structure': structure,
                    'weight': 1.0  # å°†æ¥çš„ã«é‡ã¿ä»˜ã‘ã‚‚å¯èƒ½
                })
                successful_sources.append(source)
                print(f"âœ… æˆåŠŸ: {structure['total_sections']}ã‚»ã‚¯ã‚·ãƒ§ãƒ³æŠ½å‡º")
            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {structure['error']}")
                
        except Exception as e:
            print(f"âŒ ä¾‹å¤–: {source} - {e}")
    
    if not all_structures:
        return {"error": "ã™ã¹ã¦ã®å‚è€ƒè¨˜äº‹ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # è¤‡æ•°æ§‹é€ ã‚’çµ±åˆ
    return integrate_multiple_structures(all_structures)

def integrate_multiple_structures(structures_data: list) -> dict:
    """
    è¤‡æ•°ã®è¨˜äº‹æ§‹é€ ã‚’çµ±åˆã—ã¦æœ€é©åŒ–ã•ã‚ŒãŸæ§‹é€ ã‚’ä½œæˆ
    """
    if len(structures_data) == 1:
        # 1ã¤ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return structures_data[0]['structure']
    
    # å…¨ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åé›†
    all_sections = []
    all_titles = []
    
    for data in structures_data:
        structure = data['structure']
        source = data['source']
        
        all_titles.append(structure.get('title', ''))
        
        for section in structure.get('sections', []):
            all_sections.append({
                'heading': section['heading'],
                'content': section.get('content', ''),
                'source': source,
                'weight': data['weight']
            })
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†æãƒ»çµ±åˆ
    integrated_sections = optimize_section_combination(all_sections)
    
    # ä»£è¡¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’é¸æŠï¼ˆæœ€ã‚‚é•·ã„ã‚‚ã®ã‹ã€æœ€åˆã®ã‚‚ã®ï¼‰
    representative_title = max(all_titles, key=len) if all_titles else ""
    
    return {
        "title": representative_title,
        "sections": integrated_sections[:5],  # æœ€å¤§5ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        "total_sections": len(integrated_sections[:5]),
        "source_count": len(structures_data),
        "sources": [data['source'] for data in structures_data]
    }

def optimize_section_combination(all_sections: list) -> list:
    """
    è¤‡æ•°è¨˜äº‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æœ€é©ã«çµ„ã¿åˆã‚ã›
    """
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é¡ä¼¼æ€§ã‚’åˆ†æ
    section_clusters = cluster_similar_sections(all_sections)
    
    # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰æœ€é©ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
    optimized_sections = []
    
    for cluster in section_clusters:
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã§æœ€ã‚‚å†…å®¹ãŒè±Šå¯Œãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
        best_section = max(cluster, key=lambda s: len(s.get('content', '')))
        
        # ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è‰¯ã„è¦ç´ ã‚‚çµ±åˆ
        enhanced_content = enhance_section_with_cluster(best_section, cluster)
        
        optimized_sections.append({
            'heading': best_section['heading'],
            'content': enhanced_content,
            'sources': [s['source'] for s in cluster]
        })
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆå†…å®¹ã®é•·ã•ç­‰ã§åˆ¤å®šï¼‰
    optimized_sections.sort(key=lambda s: len(s['content']), reverse=True)
    
    return optimized_sections

def cluster_similar_sections(sections: list) -> list:
    """
    é¡ä¼¼ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åŒ–
    """
    clusters = []
    processed = set()
    
    for i, section in enumerate(sections):
        if i in processed:
            continue
            
        cluster = [section]
        processed.add(i)
        
        # é¡ä¼¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        for j, other_section in enumerate(sections[i+1:], i+1):
            if j in processed:
                continue
                
            if are_sections_similar(section, other_section):
                cluster.append(other_section)
                processed.add(j)
        
        clusters.append(cluster)
    
    return clusters

def are_sections_similar(section1: dict, section2: dict) -> bool:
    """
    2ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®š
    """
    heading1 = section1['heading'].lower()
    heading2 = section2['heading'].lower()
    
    # ç°¡å˜ãªé¡ä¼¼åº¦åˆ¤å®šï¼ˆã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚‚å¯èƒ½ï¼‰
    common_words = set(heading1.split()) & set(heading2.split())
    
    # å…±é€šå˜èªãŒå¤šã„ã€ã¾ãŸã¯ç‰‡æ–¹ãŒä»–æ–¹ã‚’å«ã‚€å ´åˆã¯é¡ä¼¼ã¨ã¿ãªã™
    return len(common_words) >= 2 or heading1 in heading2 or heading2 in heading1

def enhance_section_with_cluster(main_section: dict, cluster: list) -> str:
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¦ç´ ã‚’ä½¿ã£ã¦å†…å®¹ã‚’æ‹¡å……
    """
    enhanced_content = main_section.get('content', '')
    
    # ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ‰ç”¨ãªè¦ç´ ã‚’æŠ½å‡º
    additional_insights = []
    for section in cluster:
        if section != main_section and section.get('content'):
            content = section['content']
            if len(content) > 50 and content not in enhanced_content:
                additional_insights.append(content[:100] + "...")
    
    if additional_insights:
        enhanced_content += " [è¿½åŠ ã®è¦–ç‚¹: " + " / ".join(additional_insights) + "]"
    
    return enhanced_content

def generate_article_from_multiple_references(prompt: str, integrated_structure: dict, num_sections: int = 5) -> dict:
    """
    è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹é€ ã«åŸºã¥ã„ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in integrated_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    source_count = integrated_structure.get('source_count', 1)
    sources = integrated_structure.get('sources', [])
    
    # å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿
    structure_text = f"çµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹æƒ…å ±ï¼ˆ{source_count}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆï¼‰:\n"
    structure_text += f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {integrated_structure.get('title', '')}\n\n"
    structure_text += "çµ±åˆã•ã‚ŒãŸè¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(integrated_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:150]}...\n"
        if section.get('sources'):
            structure_text += f"   ã‚½ãƒ¼ã‚¹: {len(section['sources'])}ã¤ã®è¨˜äº‹ã‹ã‚‰çµ±åˆ\n"
    
    structure_text += f"\nå‚è€ƒã«ã—ãŸã‚½ãƒ¼ã‚¹:\n"
    for i, source in enumerate(sources, 1):
        source_name = source.split('/')[-1] if '/' in source else source
        structure_text += f"- {source_name}\n"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆè¤‡æ•°å‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    title_prompt = f"""
ä»¥ä¸‹ã®è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹æˆã‚’å‚è€ƒã«ã€ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{structure_text}

è¤‡æ•°ã®è¨˜äº‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èåˆã—ã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ã§é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    
    title = generate_title_variants(title_prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆï¼ˆè¤‡æ•°å‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    lead_msg = (
        "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        f"ä»¥ä¸‹ã®{source_count}ã¤ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n\n"
        f"{structure_text}\n\n"
        "ãƒ»è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªå°å…¥ã«ã—ã¦ãã ã•ã„\n"
        "ãƒ»3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # ç« ã”ã¨ç”Ÿæˆï¼ˆçµ±åˆã•ã‚ŒãŸæ§‹é€ ã‚’æ´»ç”¨ï¼‰
    sections = []
    integrated_sections = integrated_structure.get('sections', [])
    
    for i in range(1, num_sections + 1):
        # çµ±åˆã•ã‚ŒãŸå¯¾å¿œã™ã‚‹ç« ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹
        ref_section = integrated_sections[i-1] if i-1 < len(integrated_sections) else None
        
        section_msg = (
            "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        )
        
        if ref_section:
            section_msg += f"å‚è€ƒã¨ãªã‚‹çµ±åˆç« ã®è¦‹å‡ºã—: ã€Œ{ref_section['heading']}ã€\n"
            if ref_section.get('content'):
                section_msg += f"çµ±åˆã•ã‚ŒãŸå†…å®¹æ¦‚è¦: {ref_section['content'][:200]}...\n"
            if ref_section.get('sources'):
                section_msg += f"ã“ã®ç« ã¯{len(ref_section['sources'])}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
            section_msg += "ä¸Šè¨˜ã®çµ±åˆã•ã‚ŒãŸæƒ…å ±ã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã¨åŒ…æ‹¬æ€§ã®ã‚ã‚‹å†…å®¹ã§ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
            
        section_msg += (
            "ãƒ»è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸè±Šå¯Œãªå†…å®¹ã«ã—ã¦ãã ã•ã„\n"
            "ãƒ»2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
            "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    conclusion_section = generate_conclusion_section(prompt, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "multiple_references": True,
        "source_count": source_count,
        "sources": sources
    }

def extract_style_features_from_sources(sources: list, content_types: list = None) -> dict:
    """
    è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’æŠ½å‡º
    """
    if content_types is None:
        content_types = []
        for source in sources:
            if source.startswith(('http://', 'https://')):
                content_types.append('url')
            elif source.endswith('.md'):
                content_types.append('markdown')
            else:
                content_types.append('html')
    
    all_style_features = []
    
    for i, (source, content_type) in enumerate(zip(sources, content_types)):
        print(f"ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ {i+1}/{len(sources)}: {source}")
        
        try:
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            if content_type == 'url':
                response = requests.get(source, timeout=30)
                response.raise_for_status()
                raw_content = response.text
                # HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                soup = BeautifulSoup(raw_content, 'html.parser')
                for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header']):
                    tag.decompose()
                content = soup.get_text('\n')
            elif content_type == 'markdown':
                with open(source, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:  # html
                with open(source, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                soup = BeautifulSoup(raw_content, 'html.parser')
                content = soup.get_text('\n')
            
            # ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’æŠ½å‡º
            features = analyze_style_features(content, source)
            if features:
                all_style_features.append(features)
                print(f"âœ… ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´æŠ½å‡ºå®Œäº†")
            
        except Exception as e:
            print(f"âŒ ã‚¹ã‚¿ã‚¤ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {source} - {e}")
    
    if not all_style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # è¤‡æ•°è¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’çµ±åˆ
    return merge_style_features(all_style_features)

def analyze_style_features(content: str, source: str) -> dict:
    """
    å˜ä¸€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’åˆ†æ
    """
    lines = content.split('\n')
    total_chars = len(content)
    total_lines = len(lines)
    
    # è¦‹å‡ºã—åˆ†æ
    h1_pattern = re.compile(r'^#\s+(.+)', re.MULTILINE)
    h2_pattern = re.compile(r'^##\s+(.+)', re.MULTILINE)
    h3_pattern = re.compile(r'^###\s+(.+)', re.MULTILINE)
    
    h1_matches = h1_pattern.findall(content)
    h2_matches = h2_pattern.findall(content)
    h3_matches = h3_pattern.findall(content)
    
    all_headings = h1_matches + h2_matches + h3_matches
    
    # çµµæ–‡å­—åˆ†æ
    emoji_pattern = re.compile(r'[ï¿½ï¿½ğŸ”¥ğŸ’¡ğŸ“ŠğŸ¯âš¡ğŸŒŸâœ¨ğŸ“ˆğŸ‰ğŸ’ªğŸ”§ğŸ“ğŸ†•ğŸ‘ğŸ”ğŸ“šğŸ¨ğŸª]')
    emoji_in_headings = sum(1 for h in all_headings if emoji_pattern.search(h))
    total_emojis = len(emoji_pattern.findall(content))
    
    # ç®‡æ¡æ›¸ãåˆ†æ
    bullet_patterns = [
        re.compile(r'^\s*[-â€¢*]\s+', re.MULTILINE),
        re.compile(r'^\s*\d+\.\s+', re.MULTILINE),
    ]
    total_bullets = sum(len(pattern.findall(content)) for pattern in bullet_patterns)
    
    # æ–‡ä½“åˆ†æ
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
    sentences = [s.strip() for s in sentences if s.strip()]
    avg_sentence_length = sum(len(s) for s in sentences) / max(1, len(sentences))
    
    # å°‚é–€ç”¨èªãƒ»è‹±èªåˆ†æ
    english_words = re.findall(r'\b[A-Za-z]{3,}\b', content)
    english_ratio = len(english_words) / max(1, len(content.split()))
    
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒ»è¡¨ã®åˆ†æ
    code_blocks = len(re.findall(r'```[\s\S]*?```', content))
    tables = len(re.findall(r'\|.+\|', content))
    
    # èªå°¾åˆ†æï¼ˆã§ã™ãƒ»ã¾ã™èª¿ vs ã§ã‚ã‚‹èª¿ï¼‰
    desu_masu = len(re.findall(r'(ã§ã™|ã¾ã™|ã§ã—ã‚‡ã†)ã€‚', content))
    de_aru = len(re.findall(r'(ã§ã‚ã‚‹|ã )ã€‚', content))
    
    word_count = len(content.split())
    
    return {
        "source": source,
        "total_chars": total_chars,
        "word_count": word_count,
        "h1_count": len(h1_matches),
        "h2_count": len(h2_matches),
        "h3_count": len(h3_matches),
        "h2_per_1000_words": (len(h2_matches) * 1000) / max(1, word_count),
        "emoji_in_headings": emoji_in_headings,
        "emoji_in_headings_ratio": emoji_in_headings / max(1, len(all_headings)),
        "total_emojis": total_emojis,
        "emoji_density": total_emojis / max(1, total_chars / 1000),
        "bullet_count": total_bullets,
        "bullet_density": total_bullets / max(1, total_lines),
        "avg_sentence_length": avg_sentence_length,
        "english_word_ratio": english_ratio,
        "code_blocks": code_blocks,
        "tables": tables,
        "desu_masu_ratio": desu_masu / max(1, desu_masu + de_aru),
        "formality_score": desu_masu / max(1, len(sentences))
    }

def merge_style_features(style_features_list: list) -> dict:
    """
    è¤‡æ•°è¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’çµ±åˆ
    """
    if len(style_features_list) == 1:
        return style_features_list[0]
    
    # æ•°å€¤ç‰¹å¾´ã®å¹³å‡ã‚’è¨ˆç®—
    numeric_features = [
        'h2_per_1000_words', 'emoji_in_headings_ratio', 'emoji_density',
        'bullet_density', 'avg_sentence_length', 'english_word_ratio',
        'desu_masu_ratio', 'formality_score'
    ]
    
    merged = {"source_count": len(style_features_list), "sources": []}
    
    for feature in numeric_features:
        values = [sf[feature] for sf in style_features_list if feature in sf]
        if values:
            merged[feature] = round(st.mean(values), 3)
    
    # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´ã®çµ±åˆ
    merged['total_code_blocks'] = sum(sf.get('code_blocks', 0) for sf in style_features_list)
    merged['total_tables'] = sum(sf.get('tables', 0) for sf in style_features_list)
    merged['sources'] = [sf.get('source', '') for sf in style_features_list]
    
    # ã‚¹ã‚¿ã‚¤ãƒ«åˆ¤å®š
    if merged.get('emoji_in_headings_ratio', 0) > 0.5:
        merged['heading_style'] = 'emoji_rich'
    elif merged.get('emoji_in_headings_ratio', 0) > 0.2:
        merged['heading_style'] = 'moderate_emoji'
    else:
        merged['heading_style'] = 'minimal_emoji'
    
    if merged.get('desu_masu_ratio', 0) > 0.7:
        merged['tone'] = 'polite'
    elif merged.get('desu_masu_ratio', 0) > 0.3:
        merged['tone'] = 'mixed'
    else:
        merged['tone'] = 'casual'
    
    if merged.get('bullet_density', 0) > 0.1:
        merged['structure_style'] = 'list_heavy'
    elif merged.get('bullet_density', 0) > 0.05:
        merged['structure_style'] = 'moderate_lists'
    else:
        merged['structure_style'] = 'paragraph_focused'
    
    return merged

def generate_style_yaml(merged_features: dict) -> str:
    """
    çµ±åˆã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‹ã‚‰YAMLã‚¬ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
    """
    style_guide = {
        "document_style": {
            "heading_frequency": f"{merged_features.get('h2_per_1000_words', 3):.1f} H2è¦‹å‡ºã— per 1000èª",
            "emoji_usage": {
                "in_headings": f"{merged_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«çµµæ–‡å­—",
                "overall_density": f"{merged_features.get('emoji_density', 0):.2f} çµµæ–‡å­— per 1000æ–‡å­—",
                "style": merged_features.get('heading_style', 'moderate_emoji')
            },
            "structure": {
                "bullet_density": f"{merged_features.get('bullet_density', 0)*100:.1f}%ã®è¡ŒãŒç®‡æ¡æ›¸ã",
                "style": merged_features.get('structure_style', 'moderate_lists'),
                "code_blocks": merged_features.get('total_code_blocks', 0) > 0,
                "tables": merged_features.get('total_tables', 0) > 0
            },
            "writing_style": {
                "tone": merged_features.get('tone', 'polite'),
                "avg_sentence_length": f"{merged_features.get('avg_sentence_length', 30):.0f}æ–‡å­—",
                "formality": merged_features.get('formality_score', 0.5),
                "english_ratio": f"{merged_features.get('english_word_ratio', 0)*100:.1f}%"
            }
        },
        "generation_rules": {
            "è¦‹å‡ºã—": "H2è¦‹å‡ºã—ã«çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨",
            "ç®‡æ¡æ›¸ã": "â€¢ ã‚’ä½¿ç”¨ã—ã€é©åº¦ãªå¯†åº¦ã§é…ç½®",
            "èªèª¿": "ã§ã™ãƒ»ã¾ã™èª¿" if merged_features.get('tone') == 'polite' else "æ··åˆèª¿",
            "æ–‡é•·": "èª­ã¿ã‚„ã™ã„é•·ã•ã«èª¿æ•´",
            "æ§‹æˆ": "è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ãæ•´ç†"
        },
        "reference_info": {
            "source_count": merged_features.get('source_count', 1),
            "analyzed_sources": merged_features.get('sources', [])
        }
    }
    
    return yaml.dump(style_guide, allow_unicode=True, default_flow_style=False, sort_keys=False)

def generate_article_with_style_guide(prompt: str, integrated_structure: dict, style_features: dict, num_sections: int = 5) -> dict:
    """
    ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in integrated_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    if "error" in style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰YAMLã‚’ç”Ÿæˆ
    style_yaml = generate_style_yaml(style_features)
    
    source_count = integrated_structure.get('source_count', 1)
    sources = integrated_structure.get('sources', [])
    
    # æ§‹é€ æƒ…å ±
    structure_text = f"çµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹æƒ…å ±ï¼ˆ{source_count}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆï¼‰:\n"
    structure_text += f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {integrated_structure.get('title', '')}\n\n"
    structure_text += "çµ±åˆã•ã‚ŒãŸè¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(integrated_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:150]}...\n"
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""
ã‚ãªãŸã¯è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

## ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆçµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹ã®ç‰¹å¾´ï¼‰
```yaml
{style_yaml}
```

## å‡ºåŠ›è¦ä»¶
- ä¸Šè¨˜YAMLã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’**å³å¯†ã«åæ˜ **ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
- ã™ã¹ã¦ **HTML** ã§æ›¸ãï¼ˆWordPressã«é©ã—ãŸå½¢å¼ï¼‰
- è¦‹å‡ºã—ã¯ &lt;h2&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—è¾¼ã¿ï¼‰
- è¦‹å‡ºã—é »åº¦: {style_features.get('h2_per_1000_words', 3):.1f}æœ¬/1000èª ç¨‹åº¦
- çµµæ–‡å­—ä½¿ç”¨: {style_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«é©åˆ‡ãªçµµæ–‡å­—
- ç®‡æ¡æ›¸ãã¯ &lt;ul&gt;&lt;li&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- ç®‡æ¡æ›¸ãå¯†åº¦: {style_features.get('bullet_density', 0)*100:.1f}%ç¨‹åº¦
- èªèª¿: {"ã§ã™ãƒ»ã¾ã™èª¿" if style_features.get('tone') == 'polite' else "è‡ªç„¶ãªæ··åˆèª¿"}
- æ–‡é•·: å¹³å‡{style_features.get('avg_sentence_length', 30):.0f}æ–‡å­—ç¨‹åº¦

## å‚è€ƒæ§‹é€ 
{structure_text}

ä¸Šè¨˜ã®æ§‹é€ ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’èåˆã—ã€ã€Œ{prompt}ã€ã«ã¤ã„ã¦åŒ…æ‹¬çš„ã§èª­ã¿ã‚„ã™ã„è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""

    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸé­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"title\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    title = json.loads(title_resp.choices[0].message.content)["title"]

    # è¨˜äº‹æœ¬æ–‡ç”Ÿæˆ
    content_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã€çµ±åˆã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦2000æ–‡å­—ç¨‹åº¦ã®è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚å‚è€ƒæ§‹é€ ã‚’æ´»ç”¨ã—ã€{num_sections}ã¤ã®ä¸»è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=3000
    )
    content = content_resp.choices[0].message.content

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, content[:1000])  # è¨˜äº‹ã®æœ€åˆã®1000æ–‡å­—ã‚’å‚è€ƒã«
    
    # FAQã‚’è¨˜äº‹ã«è¿½åŠ 
    content += "\n" + faq_section
    
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "multiple_references": True,
        "style_guided": True,
        "source_count": source_count,
        "sources": sources,
        "style_features": style_features,
        "style_yaml": style_yaml
    }

def generate_keyword_article_with_style(keyword: str, style_features: dict, num_sections: int = 5) -> dict:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’é©ç”¨ã—ãŸè¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰YAMLã‚’ç”Ÿæˆ
    style_yaml = generate_style_yaml(style_features)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""
ã‚ãªãŸã¯è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

## ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆå‚è€ƒè¨˜äº‹ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ï¼‰
```yaml
{style_yaml}
```

## å‡ºåŠ›è¦ä»¶
- ä¸Šè¨˜YAMLã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’**å³å¯†ã«åæ˜ **ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
- ã™ã¹ã¦ **HTML** ã§æ›¸ãï¼ˆWordPressã«é©ã—ãŸå½¢å¼ï¼‰
- è¦‹å‡ºã—ã¯ &lt;h2&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—è¾¼ã¿ï¼‰
- è¦‹å‡ºã—é »åº¦: {style_features.get('h2_per_1000_words', 3):.1f}æœ¬/1000èª ç¨‹åº¦
- çµµæ–‡å­—ä½¿ç”¨: {style_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«é©åˆ‡ãªçµµæ–‡å­—
- ç®‡æ¡æ›¸ãã¯ &lt;ul&gt;&lt;li&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- ç®‡æ¡æ›¸ãå¯†åº¦: {style_features.get('bullet_density', 0)*100:.1f}%ç¨‹åº¦
- **ãƒªãƒƒãƒãªè¡¨ã‚’ç©æ¥µæ´»ç”¨**: æ¯”è¼ƒãƒ»æ‰‹é †ãƒ»ãƒ‡ãƒ¼ã‚¿ã¯&lt;table&gt;&lt;tr&gt;&lt;td&gt;ã‚¿ã‚°ã§æ§‹é€ åŒ–
- **å¯¾è©±å½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹**: å®Ÿéš›ã®ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆä¾‹ï¼šã€Œã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ï¼‰
- èªèª¿: {"ã§ã™ãƒ»ã¾ã™èª¿" if style_features.get('tone') == 'polite' else "è‡ªç„¶ãªæ··åˆèª¿"}
- æ–‡é•·: å¹³å‡{style_features.get('avg_sentence_length', 30):.0f}æ–‡å­—ç¨‹åº¦
- **æœ¬æ–‡**: åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã‚’ä½¿ç”¨ã›ãšã€ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼ˆè¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼‰

## è¨˜äº‹ç”ŸæˆæŒ‡é‡ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆãƒªãƒƒãƒã‚¹ã‚¿ã‚¤ãƒ«ï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœã€ã®3åˆ—æ§‹æˆã§ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€ï¼‰
3. **FAQå½¢å¼**: Q&Aå½¢å¼ã§èª­ã¿ã‚„ã™ãæƒ…å ±ã‚’æ•´ç†
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ
5. **å…·ä½“çš„ãªäº‹ä¾‹**: å®Ÿéš›ã«ä½¿ãˆã‚‹ä¾‹ã‚’è±Šå¯Œã«æä¾›

## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è¨˜äº‹ç”Ÿæˆ
ã€Œ{keyword}ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ†ãƒ¼ãƒã«ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸè¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
- SEOã‚’æ„è­˜ã—ãŸæ§‹æˆ
- æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å†…å®¹
- å‚è€ƒè¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å¿ å®Ÿã«å†ç¾
- è¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãƒ»å…·ä½“ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
"""

    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸé­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"title\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    title = json.loads(title_resp.choices[0].message.content)["title"]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’250æ–‡å­—ç¨‹åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"lead\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # å®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    try:
        practical_examples = generate_practical_examples(keyword)
        print(f"âœ… å®Ÿè·µä¾‹ç”Ÿæˆå®Œäº†: {len(practical_examples)}æ–‡å­—")
    except Exception as e:
        print(f"âš ï¸ å®Ÿè·µä¾‹ç”Ÿæˆå¤±æ•—: {e}")
        practical_examples = ""

    # ç« ã”ã¨ç”Ÿæˆ
    sections = []
    for i in range(1, num_sections + 1):
        # 3ç« ç›®ã«å®Ÿè·µä¾‹ã‚’æŒ¿å…¥
        # è¡¨ã®ä½¿ç”¨åˆ¶é™ï¼ˆ1è¨˜äº‹ã‚ãŸã‚Š2ã¤ã¾ã§ï¼‰
        can_use_table = i <= 2  # ç¬¬1ç« ã¨ç¬¬2ç« ã®ã¿è¡¨ã‚’ä½¿ç”¨å¯èƒ½
        
        if i == 3 and practical_examples:
            user_content = f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ“ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\nğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n- ç®‡æ¡æ›¸ãï¼ˆ&lt;ul&gt;&lt;li&gt;ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ&lt;ol&gt;&lt;li&gt;ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n- å°è¦‹å‡ºã—ï¼ˆ&lt;h3&gt;ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n- å¤ªå­—ï¼ˆ&lt;strong&gt;ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\nğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\nğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n- ã“ã®ç« ã§ã¯è¡¨ã‚’ä½¿ç”¨ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®èª¬æ˜ã«é›†ä¸­ã—ã¦ãã ã•ã„\n\nä»¥ä¸‹ã®å®Ÿè·µä¾‹ã‚’æ´»ç”¨ã—ã¦å®Ÿç”¨çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚\n\nå®Ÿè·µä¾‹:\n{practical_examples}\n\nJSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        else:
            table_instruction = "ğŸ“Š è¡¨ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼ˆè¨˜äº‹å…¨ä½“ã§2ã¤ã¾ã§ï¼‰" if can_use_table else "ï¿½ï¿½ ã“ã®ç« ã§ã¯è¡¨ã¯ä½¿ç”¨ã›ãšã€æ–‡ç« ã§ã®èª¬æ˜ã‚’ä¸­å¿ƒã«ã—ã¦ãã ã•ã„"
            user_content = f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ“ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\nğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n- ç®‡æ¡æ›¸ãï¼ˆ&lt;ul&gt;&lt;li&gt;ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ&lt;ol&gt;&lt;li&gt;ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n- å°è¦‹å‡ºã—ï¼ˆ&lt;h3&gt;ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n- å¤ªå­—ï¼ˆ&lt;strong&gt;ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\nğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\nğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n- {table_instruction}\n\nå¯èƒ½ãªé™ã‚Šå…·ä½“ä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’å«ã‚ã¦å®Ÿè·µçš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚JSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(keyword, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    conclusion_section = generate_conclusion_section(keyword, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "style_guided": True,
        "keyword_based": True,
        "keyword": keyword,
        "style_features": style_features,
        "style_yaml": style_yaml
    }

def generate_practical_examples(keyword: str) -> str:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¿œã˜ãŸå®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    """
    example_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system", 
                "content": """
ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„å®Ÿè·µä¾‹ãƒ»å¯¾è©±ä¾‹ã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¿œã˜ã¦ã€èª­è€…ãŒå®Ÿéš›ã«è©¦ã›ã‚‹å…·ä½“çš„ãªä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€HTMLã§è¿”ã—ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆ3åˆ—æ§‹æˆï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®æ§‹æˆã§è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€å½¢å¼
3. **FAQå½¢å¼**: ã€ŒQ: ã‚ˆãã‚ã‚‹è³ªå•ã€ã€ŒA: ã‚ã‹ã‚Šã‚„ã™ã„å›ç­”ã€å½¢å¼
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚è¿·ã‚ãªã„1-2-3ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ

## é‡è¦ãªæŒ‡é‡
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã¯å¿…ãšå¯¾è©±å½¢å¼ã§è¡¨ç¾ï¼ˆã‚³ãƒ¼ãƒ‰é¢¨ã§ã¯ãªãã€è‡ªç„¶ãªä¼šè©±ï¼‰
- è¡¨ã¯æƒ…å ±ãŒæ•´ç†ã•ã‚Œã€åˆå¿ƒè€…ãŒä¸€ç›®ã§ç†è§£ã§ãã‚‹ã‚¹ã‚¿ã‚¤ãƒ«
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãšã€ã‚„ã•ã—ã„è¨€è‘‰ã§èª¬æ˜

JSONã§{"examples": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹å®Ÿè·µçš„ãªä¾‹ãƒ»æ¯”è¼ƒè¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=1000,
        response_format={"type": "json_object"}
    )
    
    return json.loads(example_resp.choices[0].message.content)["examples"]

def generate_faq_section(prompt: str, article_content: str) -> str:
    """
    è¨˜äº‹ã®ãƒ†ãƒ¼ãƒã«é–¢é€£ã—ãŸFAQ 3ã¤ã‚’ç”Ÿæˆï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    """
    faq_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
ã‚ãªãŸã¯èª­è€…ã®ç–‘å•ã‚’å…ˆèª­ã¿ã™ã‚‹FAQå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¨˜äº‹ãƒ†ãƒ¼ãƒã¨å†…å®¹ã‹ã‚‰ã€èª­è€…ãŒå¿…ãšæŠ±ãè³ªå•ã‚’3ã¤é¸ã‚“ã§ã€Q&Aå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›è¦ä»¶
- HTMLã§&lt;h3&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ã—ã¦FAQã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
- å„è³ªå•ã¯&lt;h4&gt;ã‚¿ã‚°ã§ã€ŒQ: è³ªå•å†…å®¹ã€å½¢å¼
- å„å›ç­”ã¯&lt;p&gt;ã‚¿ã‚°ã§ã€ŒA: å›ç­”å†…å®¹ã€å½¢å¼  
- çµµæ–‡å­—ã‚’åŠ¹æœçš„ã«æ´»ç”¨ï¼ˆè³ªå•ã«â“ã€å›ç­”ã«âœ…ãªã©ï¼‰
- åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§å›ç­”
- å®Ÿè·µçš„ã§å…·ä½“çš„ãªå†…å®¹

## FAQé¸å®šåŸºæº–
1. åˆå¿ƒè€…ãŒå¿…ãšç–‘å•ã«æ€ã†ã“ã¨
2. è¨˜äº‹ã‚’èª­ã‚“ã å¾Œã®æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
3. ã‚ˆãã‚ã‚‹èª¤è§£ã‚„æ³¨æ„ç‚¹

JSONã§{"faq": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"è¨˜äº‹ãƒ†ãƒ¼ãƒ: {prompt}\n\nè¨˜äº‹å†…å®¹ã®è¦ç´„: {article_content[:500]}..."}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    return json.loads(faq_resp.choices[0].message.content)["faq"]

def generate_conclusion_section(prompt: str, article_content: str) -> str:
    """
    è¨˜äº‹ã®ç· ã‚ã®è¨€è‘‰ã‚’2æ–‡ã§ç”Ÿæˆ
    """
    conclusion_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
ã‚ãªãŸã¯èª­è€…ã®å¿ƒã«éŸ¿ãç· ã‚ã®è¨€è‘‰ã‚’æ›¸ãå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¨˜äº‹ãƒ†ãƒ¼ãƒã¨å†…å®¹ã‹ã‚‰ã€è¨˜äº‹ã®ç· ã‚ããã‚Šã¨ã—ã¦æœ€é©ãª2æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›è¦ä»¶
- **å¿…ãš2æ–‡ã®ã¿**ã§æ§‹æˆ
- HTMLã§&lt;p&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- èª­è€…ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚‹å†…å®¹
- è¡Œå‹•ã‚’ä¿ƒã™ï¼ˆèƒŒä¸­ã‚’æŠ¼ã™ï¼‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§çµ±ä¸€
- é©åˆ‡ãªçµµæ–‡å­—ã‚’1-2å€‹ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡º
- è¨˜äº‹å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚Šã€èª­è€…ã¸ã®æ„Ÿè¬ã‚„åŠ±ã¾ã—ã‚’è¾¼ã‚ã‚‹

## æ–‡ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã€Œä»Šå›ç´¹ä»‹ã—ãŸæ–¹æ³•ã‚’å®Ÿè·µã™ã‚Œã°ã€ãã£ã¨ã€œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã‚ãªãŸã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’å¿œæ´ã—ã¦ã„ã¾ã™ï¼ï¿½ï¿½ã€
- ã€Œã€œã¸ã®ç¬¬ä¸€æ­©ã‚’è¸ã¿å‡ºã™ã®ã¯ä»Šæ—¥ã‹ã‚‰ã§ã™ã€‚ãœã²å®Ÿéš›ã«è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã­ ğŸ˜Šã€

JSONã§{"conclusion": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"è¨˜äº‹ãƒ†ãƒ¼ãƒ: {prompt}\n\nè¨˜äº‹å†…å®¹ã®è¦ç´„: {article_content[:500]}..."}
        ],
        temperature=0.7,
        max_tokens=300,
        response_format={"type": "json_object"}
    )
    return json.loads(conclusion_resp.choices[0].message.content)["conclusion"]

def generate_article_html_integrated(integrated_prompt: str, keywords: list, num_sections: int = 5) -> dict:
    """
    è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸè¨˜äº‹ã‚’HTMLã§ç”Ÿæˆï¼ˆæ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼‰
    """
    primary_keyword = keywords[0] if keywords else "AIæ´»ç”¨"
    keywords_text = "ã€".join(keywords)
    
    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_msg = (
        "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        "è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸè¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
        "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
        f"## å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n{chr(10).join([f'- {kw}' for kw in keywords])}\n\n"
        "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
        "ãƒ»å…±æ„Ÿï¼šæƒ…å ±æç¤º = 3:7ã€œ4:6 ç¨‹åº¦\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
        "ãƒ»æœ¬æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã›ãšã€ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã«ã—ã¦ãã ã•ã„\n"
        "ãƒ»ã™ã¹ã¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢æ„å›³ã«å¿œãˆã‚‹å°å…¥ã«ã™ã‚‹\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": integrated_prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # ç« ã”ã¨ç”Ÿæˆï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±åˆç‰ˆï¼‰
    sections = []
    for i in range(1, num_sections + 1):
        # è¡¨ã®ä½¿ç”¨åˆ¶é™ï¼ˆ1è¨˜äº‹ã‚ãŸã‚Š2ã¤ã¾ã§ï¼‰
        can_use_table = i <= 2  # ç¬¬1ç« ã¨ç¬¬2ç« ã®ã¿è¡¨ã‚’ä½¿ç”¨å¯èƒ½
        
        section_msg = (
            "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸè¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
            "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
            f"## å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã™ã¹ã¦è‡ªç„¶ã«å«ã‚ã¦ãã ã•ã„ï¼‰\n{chr(10).join([f'- {kw}' for kw in keywords])}\n\n"
            "ï¿½ï¿½ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n"
            "- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n"
            "- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\n"
            "ğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n"
            "- ç®‡æ¡æ›¸ãï¼ˆ<ul><li>ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n"
            "- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ<ol><li>ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n"
            "- å°è¦‹å‡ºã—ï¼ˆ<h3>ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n"
            "- å¤ªå­—ï¼ˆ<strong>ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n"
            "- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n"
            "- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\n"
            "ğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n"
            "- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n"
            "- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n"
            "- ã€Œã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§æ•™ãˆã¦ã€ã¨ä¾é ¼ã™ã‚‹ã¨è©³ã—ãæ•™ãˆã¦ãã‚Œã¾ã™ã€\n"
            "- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\n"
            f"{'ğŸ“Š è¡¨ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š' if can_use_table else 'ğŸ“„ ã“ã®ç« ã§ã¯è¡¨ã¯ä½¿ç”¨ã›ãšã€æ–‡ç« ã§ã®èª¬æ˜ã‚’ä¸­å¿ƒã«ã—ã¦ãã ã•ã„ï¼š'}\n"
            f"{'- ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®3åˆ—æ§‹æˆ' if can_use_table else '- åˆ†ã‹ã‚Šã‚„ã™ã„ç®‡æ¡æ›¸ãã§ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†'}\n"
            f"{'- ã€Œã‚¹ãƒ†ãƒƒãƒ—ã€ã€Œå†…å®¹ã€ã€Œãƒã‚¤ãƒ³ãƒˆã€ã®æ‰‹é †è¡¨' if can_use_table else '- æ®µéšçš„ãªèª¬æ˜ã§èª­è€…ã‚’ã‚µãƒãƒ¼ãƒˆ'}\n\n"
            "ğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n"
            "- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n"
            "- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n"
            f"{'- è¨˜äº‹å…¨ä½“ã§è¡¨ã¯2ã¤ã¾ã§ãªã®ã§ã€ã“ã®ç« ã§ä½¿ç”¨ã™ã‚‹å ´åˆã¯åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„' if can_use_table else '- ã“ã®ç« ã§ã¯è¡¨ã‚’ä½¿ç”¨ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®èª¬æ˜ã«é›†ä¸­ã—ã¦ãã ã•ã„'}\n\n"
            "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
            "ãƒ»å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢æ„å›³ã‚’æº€ãŸã™å†…å®¹ã‚’å«ã‚ã‚‹\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": integrated_prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±åˆç‰ˆï¼‰
    faq_section = generate_faq_section_integrated(keywords, lead_text + "\n".join(sections[:2]))
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±åˆç‰ˆï¼‰
    conclusion_section = generate_conclusion_section_integrated(keywords, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    
    return {
        "title": f"{primary_keyword}ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰",  # ä»®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå¾Œã§ç½®ãæ›ãˆï¼‰
        "content": content,
        "integrated_article": True
    }

def generate_keyword_article_with_style_integrated(integrated_prompt: str, keywords: list, style_features: dict, num_sections: int = 5) -> dict:
    """
    è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸè¨˜äº‹ã‚’ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã§ç”Ÿæˆ
    """
    primary_keyword = keywords[0] if keywords else "AIæ´»ç”¨"
    keywords_text = "ã€".join(keywords)
    
    if "error" in style_features:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return generate_article_html_integrated(integrated_prompt, keywords, num_sections)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰YAMLã‚’ç”Ÿæˆ
    style_yaml = generate_style_yaml(style_features)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆçµ±åˆç‰ˆï¼‰
    system_prompt = f"""
ã‚ãªãŸã¯è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

## ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆå‚è€ƒè¨˜äº‹ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ï¼‰
```yaml
{style_yaml}
```

## å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆSEOæœ€é©åŒ–ï¼‰
{chr(10).join([f"- {kw}" for kw in keywords])}

## å‡ºåŠ›è¦ä»¶
- ä¸Šè¨˜YAMLã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’**å³å¯†ã«åæ˜ **ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
- ã™ã¹ã¦ **HTML** ã§æ›¸ãï¼ˆWordPressã«é©ã—ãŸå½¢å¼ï¼‰
- è¦‹å‡ºã—ã¯ &lt;h2&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—è¾¼ã¿ï¼‰
- è¦‹å‡ºã—é »åº¦: {style_features.get('h2_per_1000_words', 3):.1f}æœ¬/1000èª ç¨‹åº¦
- çµµæ–‡å­—ä½¿ç”¨: {style_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«é©åˆ‡ãªçµµæ–‡å­—
- ç®‡æ¡æ›¸ãã¯ &lt;ul&gt;&lt;li&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- ç®‡æ¡æ›¸ãå¯†åº¦: {style_features.get('bullet_density', 0)*100:.1f}%ç¨‹åº¦
- **ãƒªãƒƒãƒãªè¡¨ã‚’ç©æ¥µæ´»ç”¨**: æ¯”è¼ƒãƒ»æ‰‹é †ãƒ»ãƒ‡ãƒ¼ã‚¿ã¯&lt;table&gt;&lt;tr&gt;&lt;td&gt;ã‚¿ã‚°ã§æ§‹é€ åŒ–
- **å¯¾è©±å½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹**: å®Ÿéš›ã®ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆä¾‹ï¼šã€Œã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ï¼‰
- èªèª¿: {"ã§ã™ãƒ»ã¾ã™èª¿" if style_features.get('tone') == 'polite' else "è‡ªç„¶ãªæ··åˆèª¿"}
- æ–‡é•·: å¹³å‡{style_features.get('avg_sentence_length', 30):.0f}æ–‡å­—ç¨‹åº¦
- **æœ¬æ–‡**: åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã‚’ä½¿ç”¨ã›ãšã€ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼ˆè¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼‰

## è¨˜äº‹ç”ŸæˆæŒ‡é‡ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆãƒªãƒƒãƒã‚¹ã‚¿ã‚¤ãƒ«ï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœã€ã®3åˆ—æ§‹æˆã§ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€ï¼‰
3. **FAQå½¢å¼**: Q&Aå½¢å¼ã§èª­ã¿ã‚„ã™ãæƒ…å ±ã‚’æ•´ç†
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ
5. **å…·ä½“çš„ãªäº‹ä¾‹**: å®Ÿéš›ã«ä½¿ãˆã‚‹ä¾‹ã‚’è±Šå¯Œã«æä¾›

## çµ±åˆè¨˜äº‹ç”Ÿæˆ
è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«çµ±åˆã—ã€å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢æ„å›³ã‚’æº€ãŸã™åŒ…æ‹¬çš„ãªè¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
- SEOã‚’æ„è­˜ã—ãŸæ§‹æˆ
- æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å†…å®¹
- å‚è€ƒè¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å¿ å®Ÿã«å†ç¾
- è¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãƒ»å…·ä½“ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
"""

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keywords_text}ã€ã«ã¤ã„ã¦ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’250æ–‡å­—ç¨‹åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"lead\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # å®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    try:
        practical_examples = generate_practical_examples_integrated(keywords)
        print(f"âœ… çµ±åˆå®Ÿè·µä¾‹ç”Ÿæˆå®Œäº†: {len(practical_examples)}æ–‡å­—")
    except Exception as e:
        print(f"âš ï¸ çµ±åˆå®Ÿè·µä¾‹ç”Ÿæˆå¤±æ•—: {e}")
        practical_examples = ""

    # ç« ã”ã¨ç”Ÿæˆ
    sections = []
    for i in range(1, num_sections + 1):
        # 3ç« ç›®ã«å®Ÿè·µä¾‹ã‚’æŒ¿å…¥
        # è¡¨ã®ä½¿ç”¨åˆ¶é™ï¼ˆ1è¨˜äº‹ã‚ãŸã‚Š2ã¤ã¾ã§ï¼‰
        can_use_table = i <= 2  # ç¬¬1ç« ã¨ç¬¬2ç« ã®ã¿è¡¨ã‚’ä½¿ç”¨å¯èƒ½
        
        if i == 3 and practical_examples:
            user_content = f"è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keywords_text}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ“ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\nğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n- ç®‡æ¡æ›¸ãï¼ˆ&lt;ul&gt;&lt;li&gt;ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ&lt;ol&gt;&lt;li&gt;ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n- å°è¦‹å‡ºã—ï¼ˆ&lt;h3&gt;ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n- å¤ªå­—ï¼ˆ&lt;strong&gt;ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\nğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\nğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n- ã“ã®ç« ã§ã¯è¡¨ã‚’ä½¿ç”¨ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆã§ã®èª¬æ˜ã«é›†ä¸­ã—ã¦ãã ã•ã„\n\nä»¥ä¸‹ã®å®Ÿè·µä¾‹ã‚’æ´»ç”¨ã—ã¦å®Ÿç”¨çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚\n\nå®Ÿè·µä¾‹:\n{practical_examples}\n\nJSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        else:
            table_instruction = "ğŸ“Š è¡¨ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼ˆè¨˜äº‹å…¨ä½“ã§2ã¤ã¾ã§ï¼‰" if can_use_table else "ğŸ“„ ã“ã®ç« ã§ã¯è¡¨ã¯ä½¿ç”¨ã›ãšã€æ–‡ç« ã§ã®èª¬æ˜ã‚’ä¸­å¿ƒã«ã—ã¦ãã ã•ã„"
            user_content = f"è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keywords_text}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ“ æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼š\n- æœ¬æ–‡ã®åœ°ã®æ–‡ã§ã¯çµµæ–‡å­—ã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ï¼‰\n- è¡¨å†…ã§ã®çµµæ–‡å­—ä½¿ç”¨ã¯å¯ï¼ˆè¦–è¦šçš„ãªæ•´ç†ã«åŠ¹æœçš„ï¼‰\n\nğŸ¨ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼š\n- ç®‡æ¡æ›¸ãï¼ˆ&lt;ul&gt;&lt;li&gt;ï¼‰ã§é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†\n- ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ&lt;ol&gt;&lt;li&gt;ï¼‰ã§æ‰‹é †ã‚„é †åºã‚’æ˜ç¢ºåŒ–\n- å°è¦‹å‡ºã—ï¼ˆ&lt;h3&gt;ï¼‰ã§å†…å®¹ã‚’ç´°ã‹ãåŒºåˆ‡ã‚‹\n- å¤ªå­—ï¼ˆ&lt;strong&gt;ï¼‰ã§è¦ç‚¹ã‚’å¼·èª¿\n- é•·ã„æ®µè½ã¯é©åº¦ã«åˆ†å‰²ã—ã€èª­ã¿ã‚„ã™ãæ§‹æˆ\n- æƒ…å ±ã‚’éšå±¤åŒ–ã—ã¦ç†è§£ã—ã‚„ã™ãã™ã‚‹\n\nğŸ¯ ãŠã™ã™ã‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç©æ¥µçš„ã«å«ã‚ã¦ãã ã•ã„ï¼š\n- ã€ŒChatGPTã«ã€å…·ä½“çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n- ã€Œã€ã€œã‚’åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã¿ã¦ãã ã•ã„ã€\n- å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’2-3å€‹å«ã‚ã¦ãã ã•ã„\n\nğŸ“Œ é‡è¦ãªåˆ¶ç´„ï¼š\n- FAQã¯æœ€å¾Œã«ä¸€æ‹¬ã§è¨˜è¿°ã™ã‚‹ãŸã‚ã€ã“ã®ç« ã§ã¯FAQå½¢å¼ã®è¡¨ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„\n- Q&Aå½¢å¼ã®å†…å®¹ã¯é¿ã‘ã€èª¬æ˜ã‚„æ‰‹é †ã‚’ä¸­å¿ƒã«è¨˜è¿°ã—ã¦ãã ã•ã„\n- {table_instruction}\n\nå¯èƒ½ãªé™ã‚Šå…·ä½“ä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’å«ã‚ã¦å®Ÿè·µçš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢æ„å›³ã‚’æº€ãŸã™å†…å®¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚JSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section_integrated(keywords, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    conclusion_section = generate_conclusion_section_integrated(keywords, lead_text + "\n".join(sections) + "\n" + faq_section)
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section + "\n" + conclusion_section
    
    return {
        "title": f"{primary_keyword}ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰",  # ä»®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå¾Œã§ç½®ãæ›ãˆï¼‰
        "content": content,
        "reference_used": True,
        "style_guided": True,
        "keyword_based": True,
        "integrated_article": True,
        "keywords_used": keywords,
        "primary_keyword": primary_keyword,
        "style_features": style_features,
        "style_yaml": style_yaml
    }

def generate_practical_examples_integrated(keywords: list) -> str:
    """
    çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¿œã˜ãŸå®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    """
    keywords_text = "ã€".join(keywords)
    primary_keyword = keywords[0] if keywords else "AIæ´»ç”¨"
    
    example_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system", 
                "content": """
ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„å®Ÿè·µä¾‹ãƒ»å¯¾è©±ä¾‹ã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ±åˆã—ã¦ã€èª­è€…ãŒå®Ÿéš›ã«è©¦ã›ã‚‹å…·ä½“çš„ãªä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€HTMLã§è¿”ã—ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆ3åˆ—æ§‹æˆï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®æ§‹æˆã§è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€å½¢å¼
3. **FAQå½¢å¼**: ã€ŒQ: ã‚ˆãã‚ã‚‹è³ªå•ã€ã€ŒA: ã‚ã‹ã‚Šã‚„ã™ã„å›ç­”ã€å½¢å¼
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚è¿·ã‚ãªã„1-2-3ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ

## é‡è¦ãªæŒ‡é‡
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã¯å¿…ãšå¯¾è©±å½¢å¼ã§è¡¨ç¾ï¼ˆã‚³ãƒ¼ãƒ‰é¢¨ã§ã¯ãªãã€è‡ªç„¶ãªä¼šè©±ï¼‰
- è¡¨ã¯æƒ…å ±ãŒæ•´ç†ã•ã‚Œã€åˆå¿ƒè€…ãŒä¸€ç›®ã§ç†è§£ã§ãã‚‹ã‚¹ã‚¿ã‚¤ãƒ«
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãšã€ã‚„ã•ã—ã„è¨€è‘‰ã§èª¬æ˜
- è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«çµ±åˆã—ãŸå†…å®¹

JSONã§{"examples": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keywords_text}ã€ã«é–¢ã™ã‚‹å®Ÿè·µçš„ãªä¾‹ãƒ»æ¯”è¼ƒè¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’çµ±åˆã—ã¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=1000,
        response_format={"type": "json_object"}
    )
    
    return json.loads(example_resp.choices[0].message.content)["examples"]

def generate_faq_section_integrated(keywords: list, article_content: str) -> str:
    """
    çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«é–¢é€£ã—ãŸFAQ 3ã¤ã‚’ç”Ÿæˆï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    """
    keywords_text = "ã€".join(keywords)
    primary_keyword = keywords[0] if keywords else "AIæ´»ç”¨"
    
    faq_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
ã‚ãªãŸã¯èª­è€…ã®ç–‘å•ã‚’å…ˆèª­ã¿ã™ã‚‹FAQå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨è¨˜äº‹å†…å®¹ã‹ã‚‰ã€èª­è€…ãŒå¿…ãšæŠ±ãè³ªå•ã‚’3ã¤é¸ã‚“ã§ã€Q&Aå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›è¦ä»¶
- HTMLã§&lt;h3&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ã—ã¦FAQã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
- å„è³ªå•ã¯&lt;h4&gt;ã‚¿ã‚°ã§ã€ŒQ: è³ªå•å†…å®¹ã€å½¢å¼
- å„å›ç­”ã¯&lt;p&gt;ã‚¿ã‚°ã§ã€ŒA: å›ç­”å†…å®¹ã€å½¢å¼  
- çµµæ–‡å­—ã‚’åŠ¹æœçš„ã«æ´»ç”¨ï¼ˆè³ªå•ã«â“ã€å›ç­”ã«âœ…ãªã©ï¼‰
- åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§å›ç­”
- å®Ÿè·µçš„ã§å…·ä½“çš„ãªå†…å®¹
- è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ãŸè³ªå•

## FAQé¸å®šåŸºæº–
1. åˆå¿ƒè€…ãŒå¿…ãšç–‘å•ã«æ€ã†ã“ã¨
2. è¨˜äº‹ã‚’èª­ã‚“ã å¾Œã®æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
3. ã‚ˆãã‚ã‚‹èª¤è§£ã‚„æ³¨æ„ç‚¹
4. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é–“ã®é–¢é€£æ€§ã«é–¢ã™ã‚‹è³ªå•

JSONã§{"faq": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords_text}\n\nè¨˜äº‹å†…å®¹ã®è¦ç´„: {article_content[:500]}..."}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    return json.loads(faq_resp.choices[0].message.content)["faq"]

def generate_conclusion_section_integrated(keywords: list, article_content: str) -> str:
    """
    çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¨˜äº‹ã®ç· ã‚ã®è¨€è‘‰ã‚’2æ–‡ã§ç”Ÿæˆ
    """
    keywords_text = "ã€".join(keywords)
    primary_keyword = keywords[0] if keywords else "AIæ´»ç”¨"
    
    conclusion_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
ã‚ãªãŸã¯èª­è€…ã®å¿ƒã«éŸ¿ãç· ã‚ã®è¨€è‘‰ã‚’æ›¸ãå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨è¨˜äº‹å†…å®¹ã‹ã‚‰ã€è¨˜äº‹ã®ç· ã‚ããã‚Šã¨ã—ã¦æœ€é©ãª2æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›è¦ä»¶
- **å¿…ãš2æ–‡ã®ã¿**ã§æ§‹æˆ
- HTMLã§&lt;p&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- èª­è€…ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã‚‹å†…å®¹
- è¡Œå‹•ã‚’ä¿ƒã™ï¼ˆèƒŒä¸­ã‚’æŠ¼ã™ï¼‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§çµ±ä¸€
- é©åˆ‡ãªçµµæ–‡å­—ã‚’1-2å€‹ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡º
- è¨˜äº‹å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚Šã€èª­è€…ã¸ã®æ„Ÿè¬ã‚„åŠ±ã¾ã—ã‚’è¾¼ã‚ã‚‹
- è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®çµ±åˆçš„ãªæ´»ç”¨ã‚’ä¿ƒã™å†…å®¹

## æ–‡ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã€Œä»Šå›ç´¹ä»‹ã—ãŸæ–¹æ³•ã‚’å®Ÿè·µã™ã‚Œã°ã€ãã£ã¨ã€œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã‚ãªãŸã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’å¿œæ´ã—ã¦ã„ã¾ã™ï¼ğŸš€ã€
- ã€Œã€œã¸ã®ç¬¬ä¸€æ­©ã‚’è¸ã¿å‡ºã™ã®ã¯ä»Šæ—¥ã‹ã‚‰ã§ã™ã€‚ãœã²å®Ÿéš›ã«è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã­ ğŸ˜Šã€

JSONã§{"conclusion": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords_text}\n\nè¨˜äº‹å†…å®¹ã®è¦ç´„: {article_content[:500]}..."}
        ],
        temperature=0.7,
        max_tokens=300,
        response_format={"type": "json_object"}
    )
    return json.loads(conclusion_resp.choices[0].message.content)["conclusion"]

if __name__ == "__main__":
    # æ–°ã—ã„çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
    print("=== çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        keyword_group = get_next_keyword_group()
        print(f"å–å¾—ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚°ãƒ«ãƒ¼ãƒ—:")
        print(f"  ã‚°ãƒ«ãƒ¼ãƒ—ID: {keyword_group['group_id']}")
        print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keyword_group['keywords'])}")
        print(f"  ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒª: {keyword_group['main_category']}")
        print(f"  ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª: {keyword_group['sub_category']}")
        
        # çµ±åˆè¨˜äº‹ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\n=== çµ±åˆè¨˜äº‹ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
        article = generate_integrated_article_from_keywords(keyword_group)
        print(f"ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {article['title']}")
        print(f"è¨˜äº‹ã®å†’é ­: {article['content'][:200]}...")
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨")
        keyword = get_next_keyword(col=0)
        prompt = f"{keyword}ã«ã¤ã„ã¦ã®è¨˜äº‹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚SEOã‚’æ„è­˜ã—ã¦ã€æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"
        print("â˜…ä»Šå›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:", prompt)
        article = generate_article_html(prompt)
        print(f"ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {article['title']}")
        print(f"è¨˜äº‹ã®å†’é ­: {article['content'][:200]}...")

