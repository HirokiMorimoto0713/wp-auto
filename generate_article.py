import os
import openai
import json
import re
import csv
import requests
import yaml
import statistics as st
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# .env ã‹ã‚‰ APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

KEYWORDS_CSV = "keywords.csv"
INDEX_FILE = "last_index.txt"

def get_next_keyword(col: int = 0) -> str:
    idx = 0
    if os.path.exists(INDEX_FILE):
        with open(INDEX_FILE) as f:
            idx = int(f.read().strip() or 0)
    with open(KEYWORDS_CSV, encoding="utf-8") as f:
        reader = csv.reader(f)
        next(reader)  # 1è¡Œã‚¹ã‚­ãƒƒãƒ—
        keywords = [row[col] for row in reader if len(row) > col]
    keyword = keywords[idx % len(keywords)]
    with open(INDEX_FILE, "w") as f:
        f.write(str((idx + 1) % len(keywords)))
    return keyword

def generate_title_variants(prompt: str, n: int = 5) -> list[str]:
    """
    ãƒ†ãƒ¼ãƒ(prompt)ã«åˆã†"ã‚¤ã‚±ã¦ã‚‹"æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’nå€‹ç”Ÿæˆ
    """
    style_examples = [
        "ã‚‚ã†è¿·ã‚ãªã„ã€‚åˆå¿ƒè€…ã§ã‚‚ã§ãã‚‹ã€‡ã€‡ã®å§‹ã‚æ–¹",
        "ã“ã‚Œã‚’çŸ¥ã‚‰ãšã«ã€‡ã€‡å§‹ã‚ã‚‹ã®ã¯æã—ã¦ã‚‹",
        "æ­£ç›´ã—ã‚“ã©ã„ã€‚ã§ã‚‚ã€‡ã€‡ã§äººç”Ÿå¤‰ã‚ã£ãŸè©±",
        "2å¹´é–“ã®å¤±æ•—ã‚’çµŒã¦ã€ã‚„ã£ã¨è¦‹ã¤ã‘ãŸã€‡ã€‡",
        "å³é¸7é¸ï½œ2024å¹´æœ€æ–°ã®ãŠã™ã™ã‚ã€‡ã€‡ã‚’ç´¹ä»‹"
    ]

    examples_text = "\n".join([f"- {ex}" for ex in style_examples])

    system_prompt = (
        "ã‚ãªãŸã¯SEOã¨èª­è€…å¿ƒç†ã«é•·ã‘ãŸãƒ–ãƒ­ã‚°ç·¨é›†è€…ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã®æ–‡ä½“ãƒ»æ§‹æˆãƒ»èªæ„Ÿãƒ»ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’å‚è€ƒã«ã€\n"
        "ä¸ãˆã‚‰ã‚ŒãŸãƒ†ãƒ¼ãƒã«å¯¾ã™ã‚‹é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’è¤‡æ•°ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã‚’ãã®ã¾ã¾ä½¿ã†ã“ã¨ã¯è¨±ã—ã¾ã›ã‚“ã€‚\n"
        "ã‚¿ã‚¤ãƒˆãƒ«ä¾‹:\n" + examples_text + "\n"
        "å‡ºåŠ›ã¯JSONå½¢å¼ã§ â†’ {\"titles\": [\"â€¦\", \"â€¦\", â€¦]}"
    )

    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": prompt}
        ],
        temperature=0.95,
        max_tokens=500,
        response_format={"type": "json_object"}
    )
    return json.loads(resp.choices[0].message.content)["titles"]

def generate_article_html(prompt: str, num_sections: int = 5) -> dict:
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title = generate_title_variants(prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_msg = (
    "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
        "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
        "ğŸ¨ çµµæ–‡å­—ã®ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼š\n"
        "- æ–‡ç« ã®ç´„20%ã«é©åˆ‡ãªçµµæ–‡å­—ã‚’è‡ªç„¶ã«é…ç½®\n"
        "- è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡ºã™ã‚‹çµµæ–‡å­—ï¼ˆğŸ˜Š ğŸ’¡ âœ¨ ğŸ¯ ğŸ“ ğŸš€ãªã©ï¼‰ã‚’åŠ¹æœçš„ã«æ´»ç”¨\n\n"
    "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
        "ãƒ»å…±æ„Ÿï¼šæƒ…å ±æç¤º = 3:7ã€œ4:6 ç¨‹åº¦\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]


    # ç« ã”ã¨ç”Ÿæˆ
    sections = []
    for i in range(1, num_sections + 1):
        section_msg = (
            "ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„SEOãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            "ã“ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
            "ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„ã€‚\n\n"
            "ğŸ¨ çµµæ–‡å­—ã®ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼š\n"
            "- æœ¬æ–‡ã®ç´„20%ã®æ–‡ã«é©åˆ‡ãªçµµæ–‡å­—ã‚’è‡ªç„¶ã«é…ç½®\n"
            "- æ„Ÿæƒ…è¡¨ç¾ï¼ˆğŸ˜Š ğŸ¤” ğŸ˜…ï¼‰ã€å¼·èª¿ï¼ˆâœ¨ ğŸ¯ ğŸ’¡ï¼‰ã€è¦–è¦šçš„ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼ˆğŸ“ ğŸš€ â­ï¼‰ã‚’åŠ¹æœçš„ã«æ´»ç”¨\n"
            "- æ–‡æœ«ã‚„é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã§çµµæ–‡å­—ã‚’ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡º\n\n"
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãŒå¿…è¦ãªå ´åˆã¯ã€ä»¥ä¸‹ã®å½¢å¼ã§å¯¾è©±å½¢å¼ã§è¡¨ç¾ã—ã¦ãã ã•ã„ï¼š\n"
            "âŒ ã‚³ãƒ¼ãƒ‰é¢¨: ```ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹```\n"
            "âœ… å¯¾è©±é¢¨: ã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€\n\n"
            "è¡¨ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n"
            "- ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®3åˆ—æ§‹æˆ\n"
            "- ã€ŒQ: è³ªå•ã€ã€ŒA: å›ç­”ã€ã®FAQå½¢å¼\n"
            "- ã€Œã‚¹ãƒ†ãƒƒãƒ—ã€ã€Œå†…å®¹ã€ã€Œãƒã‚¤ãƒ³ãƒˆã€ã®æ‰‹é †è¡¨\n\n"
            "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤ï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section
    return {
        "title": title,
        "content": content
    }


def generate_image_prompt(article_body: str) -> str:
    """
    è¨˜äº‹æœ¬æ–‡HTMLã‹ã‚‰è‹±èªã®ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    """
    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": (
                    "ã‚ãªãŸã¯ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚"
                    "ä»¥ä¸‹ã®HTMLå½¢å¼ã®è¨˜äº‹ã«åˆã£ãŸã€éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒŸãƒ‹ãƒãƒ«ãªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®"
                    "è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’1æ–‡ã ã‘ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\n"
                    "è¦ä»¶ï¼š\n"
                    "- flat design, minimalist style ã‚’å¿…ãšå«ã‚ã‚‹\n"
                    "- è¤‡é›‘ãªè¦ç´ ã¯é¿ã‘ã€2-3å€‹ã®åŸºæœ¬çš„ãªè¦ç´ ã®ã¿\n"
                    "- ãƒ‘ã‚¹ãƒ†ãƒ«ã‚«ãƒ©ãƒ¼ã¾ãŸã¯ç™½èƒŒæ™¯ã‚’ä½¿ç”¨\n"
                    "- ã‚¢ã‚¤ã‚³ãƒ³ã‚„ã‚¤ãƒ©ã‚¹ãƒˆé¢¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚¶ã‚¤ãƒ³\n"
                    "- æ–‡å­—ã‚„ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„\n"
                    "- ä¾‹: 'Simple flat design icon of a lightbulb on white background, minimalist style, pastel colors'"
                )
            },
            {"role": "user", "content": article_body}
        ],
        temperature=0.5,
        max_tokens=200
    )
    return resp.choices[0].message.content.strip()


def generate_image_url(image_prompt: str) -> str:
    """
    DALLÂ·E 3 ã«ç”»åƒç”Ÿæˆã‚’é ¼ã¿ã€URLã‚’è¿”ã™
    """
    response = openai.images.generate(
        model="dall-e-3",
        prompt=image_prompt,
        size="1792x1024",
        n=1
    )
    image_url = response.data[0].url
    return image_url


def generate_meta_description(prompt: str, content: str) -> str:
    """
    è¨˜äº‹ã®meta descriptionã‚’ç”Ÿæˆï¼ˆ150-160æ–‡å­—ç¨‹åº¦ï¼‰
    """
    desc_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®meta descriptionï¼ˆæ¤œç´¢çµæœã«è¡¨ç¤ºã•ã‚Œã‚‹èª¬æ˜æ–‡ï¼‰ã‚’æ—¥æœ¬èªã§150æ–‡å­—ä»¥å†…ã§æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã‚ˆã†ãªé­…åŠ›çš„ãªæ–‡ç« \n"
        "ãƒ»è¨˜äº‹ã®è¦ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹\n"
        "ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«å«ã‚ã‚‹\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§çµ±ä¸€\n"
        "JSONã§{\"description\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    desc_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": desc_msg},
            {"role": "user", "content": f"ãƒ†ãƒ¼ãƒ: {prompt}\nè¨˜äº‹å†…å®¹: {content[:500]}..."}
        ],
        temperature=0.5,
        max_tokens=300,
        response_format={"type": "json_object"}
    )
    return json.loads(desc_resp.choices[0].message.content)["description"]


def generate_seo_tags(prompt: str, content: str) -> list[str]:
    """
    è¨˜äº‹ã®SEOåŠ¹æœçš„ãªWordPressã‚¿ã‚°ã‚’3ã¤ç”Ÿæˆ
    """
    tags_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€å®¶ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã«æœ€é©ãªWordPressã‚¿ã‚°ã‚’3ã¤é¸ã‚“ã§ãã ã•ã„ã€‚\n"
        "ãƒ»SEOåŠ¹æœãŒé«˜ãã€æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n"
        "ãƒ»è¨˜äº‹å†…å®¹ã¨é–¢é€£æ€§ãŒé«˜ã„ã‚‚ã®\n"
        "ãƒ»ä¸€èˆ¬çš„ã™ããšã€å…·ä½“çš„ã™ããªã„é©åº¦ãªç²’åº¦\n"
        "ãƒ»æ—¥æœ¬èªã§ã€å„ã‚¿ã‚°ã¯2-4æ–‡å­—ç¨‹åº¦\n"
        "ãƒ»ä¾‹: 'AI', 'ChatGPT', 'ç„¡æ–™ãƒ„ãƒ¼ãƒ«', 'åˆå¿ƒè€…å‘ã‘' ãªã©\n"
        "JSONã§{\"tags\": [\"ã‚¿ã‚°1\", \"ã‚¿ã‚°2\", \"ã‚¿ã‚°3\"]}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    tags_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": tags_msg},
            {"role": "user", "content": f"ãƒ†ãƒ¼ãƒ: {prompt}\nè¨˜äº‹å†…å®¹: {content[:300]}..."}
        ],
        temperature=0.5,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    return json.loads(tags_resp.choices[0].message.content)["tags"]


def generate_seo_slug(prompt: str, title: str) -> str:
    """
    è¨˜äº‹ã®SEOåŠ¹æœçš„ãªã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚¹ãƒ©ãƒƒã‚°ã‚’ç”Ÿæˆï¼ˆ3-5èªç¨‹åº¦ï¼‰
    """
    slug_msg = (
        "ã‚ãªãŸã¯SEOå°‚é–€å®¶ã§ã™ã€‚\n"
        "ã“ã®è¨˜äº‹ã®WordPressã‚¹ãƒ©ãƒƒã‚°ï¼ˆURLï¼‰ã‚’è‹±èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»3-5èªç¨‹åº¦ã®çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚º\n"
        "ãƒ»ãƒã‚¤ãƒ•ãƒ³ã§åŒºåˆ‡ã‚‹ï¼ˆä¾‹: chatgpt-free-guideï¼‰\n"
        "ãƒ»SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€\n"
        "ãƒ»è¨˜äº‹å†…å®¹ã‚’è¡¨ã™åˆ†ã‹ã‚Šã‚„ã™ã„è‹±èª\n"
        "ãƒ»å°æ–‡å­—ã®ã¿ä½¿ç”¨\n"
        "ãƒ»æ•°å­—ã¯ä½¿ç”¨å¯èƒ½\n"
        "JSONã§{\"slug\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    slug_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": slug_msg},
            {"role": "user", "content": f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {prompt}\nã‚¿ã‚¤ãƒˆãƒ«: {title}"}
        ],
        temperature=0.3,
        max_tokens=150,
        response_format={"type": "json_object"}
    )
    return json.loads(slug_resp.choices[0].message.content)["slug"]


def extract_article_structure(url_or_content: str, content_type: str = "url") -> dict:
    """
    å‚è€ƒè¨˜äº‹ã‹ã‚‰HTMLã¾ãŸã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®æ§‹é€ ã‚’æŠ½å‡º
    content_type: "url", "html", "markdown"
    """
    if content_type == "url":
        # URLã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
        try:
            response = requests.get(url_or_content, timeout=30)
            response.raise_for_status()
            html_content = response.text
        except Exception as e:
            print(f"URLå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
            
        # HTMLã‹ã‚‰æ§‹é€ æŠ½å‡º
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
        for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            tag.decompose()
            
        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
        title = ""
        if soup.find('h1'):
            title = soup.find('h1').get_text().strip()
        elif soup.find('title'):
            title = soup.find('title').get_text().strip()
            
        # è¦‹å‡ºã—ã¨å†…å®¹æŠ½å‡º
        sections = []
        for i, heading in enumerate(soup.find_all(['h2', 'h3', 'h4'])):
            heading_text = heading.get_text().strip()
            
            # è¦‹å‡ºã—å¾Œã®å†…å®¹ã‚’å–å¾—
            content_parts = []
            current = heading.next_sibling
            while current and current.name not in ['h1', 'h2', 'h3', 'h4']:
                if hasattr(current, 'get_text'):
                    text = current.get_text().strip()
                    if text and len(text) > 10:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                        content_parts.append(text)
                current = current.next_sibling
                if len(content_parts) > 3:  # é•·ã™ãã‚‹å ´åˆã¯åˆ¶é™
                    break
                    
            sections.append({
                "heading": heading_text,
                "content": " ".join(content_parts)[:200] + "..." if content_parts else ""
            })
            
            if len(sections) >= 5:  # æœ€å¤§5ã¤ã¾ã§
                break
        
        return {
            "title": title,
            "sections": sections,
            "total_sections": len(sections)
        }
        
    elif content_type == "html":
        # HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ç›´æ¥æŠ½å‡º
        soup = BeautifulSoup(url_or_content, 'html.parser')
        # ä¸Šè¨˜ã¨åŒã˜å‡¦ç†...
        
    elif content_type == "markdown":
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‹ã‚‰æ§‹é€ æŠ½å‡º
        lines = url_or_content.split('\n')
        sections = []
        current_section = None
        
        for line in lines:
            if line.startswith('#'):
                if current_section:
                    sections.append(current_section)
                    
                level = len(line) - len(line.lstrip('#'))
                heading = line.lstrip('# ').strip()
                current_section = {
                    "heading": heading,
                    "content": "",
                    "level": level
                }
            elif current_section and line.strip():
                current_section["content"] += line + " "
                
        if current_section:
            sections.append(current_section)
            
        # h2ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿æŠ½å‡º
        h2_sections = [s for s in sections if s.get("level", 0) == 2][:5]
        
        return {
            "title": next((s["heading"] for s in sections if s.get("level", 0) == 1), ""),
            "sections": h2_sections,
            "total_sections": len(h2_sections)
        }
    
    return {"error": "ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—"}

def generate_article_from_reference(prompt: str, reference_structure: dict, num_sections: int = 5) -> dict:
    """
    å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã«åŸºã¥ã„ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in reference_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®æ§‹é€ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿
    structure_text = f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {reference_structure.get('title', '')}\n\n"
    structure_text += "å‚è€ƒè¨˜äº‹ã®è¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(reference_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:100]}...\n"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    title_prompt = f"""
ä»¥ä¸‹ã®å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚’å‚è€ƒã«ã€ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{structure_text}

å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã®ã‚ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    
    title = generate_title_variants(title_prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    lead_msg = (
        "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "ä»¥ä¸‹ã®å‚è€ƒè¨˜äº‹ã®æ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n\n"
        f"{structure_text}\n\n"
        "ãƒ»3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
        "ãƒ»ãƒªã‚ºãƒ ã‚’ä»˜ã‘ã‚‹ãŸã‚æ¥µç«¯ã«é•·ã„æ–‡ã‚’é¿ã‘ã€å¥ç‚¹ã§é©åº¦ã«åˆ†å‰²\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # ç« ã”ã¨ç”Ÿæˆï¼ˆå‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’æ´»ç”¨ï¼‰
    sections = []
    ref_sections = reference_structure.get('sections', [])
    
    for i in range(1, num_sections + 1):
        # å‚è€ƒè¨˜äº‹ã®å¯¾å¿œã™ã‚‹ç« ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹
        ref_section = ref_sections[i-1] if i-1 < len(ref_sections) else None
        
        section_msg = (
            "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        )
        
        if ref_section:
            section_msg += f"å‚è€ƒã¨ãªã‚‹ç« ã®è¦‹å‡ºã—: ã€Œ{ref_section['heading']}ã€\n"
            if ref_section.get('content'):
                section_msg += f"å‚è€ƒç« ã®å†…å®¹æ¦‚è¦: {ref_section['content'][:150]}...\n"
            section_msg += "ä¸Šè¨˜ã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã®ã‚ã‚‹å†…å®¹ã§ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
            
        section_msg += (
            "ãƒ»2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
            "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section
    return {
        "title": title,
        "content": content,
        "reference_used": True
    }

def extract_multiple_article_structures(sources: list, content_types: list = None) -> dict:
    """
    è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‹ã‚‰æ§‹é€ ã‚’æŠ½å‡ºãƒ»çµ±åˆ
    sources: URLã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    content_types: å„ã‚½ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ ["url", "file", "markdown", "html"]
    """
    if content_types is None:
        # è‡ªå‹•åˆ¤å®š
        content_types = []
        for source in sources:
            if source.startswith(('http://', 'https://')):
                content_types.append('url')
            elif source.endswith('.md'):
                content_types.append('markdown')
            else:
                content_types.append('html')
    
    all_structures = []
    successful_sources = []
    
    for i, (source, content_type) in enumerate(zip(sources, content_types)):
        print(f"ğŸ“– å‚è€ƒè¨˜äº‹ {i+1}/{len(sources)} ã‚’å‡¦ç†ä¸­: {source}")
        
        try:
            if content_type == 'url':
                structure = extract_article_structure(source, "url")
            elif content_type in ['markdown', 'html']:
                if content_type == 'markdown':
                    with open(source, 'r', encoding='utf-8') as f:
                        content = f.read()
                    structure = extract_article_structure(content, "markdown")
                else:
                    with open(source, 'r', encoding='utf-8') as f:
                        content = f.read()
                    structure = extract_article_structure(content, "html")
            
            if "error" not in structure:
                all_structures.append({
                    'source': source,
                    'structure': structure,
                    'weight': 1.0  # å°†æ¥çš„ã«é‡ã¿ä»˜ã‘ã‚‚å¯èƒ½
                })
                successful_sources.append(source)
                print(f"âœ… æˆåŠŸ: {structure['total_sections']}ã‚»ã‚¯ã‚·ãƒ§ãƒ³æŠ½å‡º")
            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {structure['error']}")
                
        except Exception as e:
            print(f"âŒ ä¾‹å¤–: {source} - {e}")
    
    if not all_structures:
        return {"error": "ã™ã¹ã¦ã®å‚è€ƒè¨˜äº‹ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # è¤‡æ•°æ§‹é€ ã‚’çµ±åˆ
    return integrate_multiple_structures(all_structures)

def integrate_multiple_structures(structures_data: list) -> dict:
    """
    è¤‡æ•°ã®è¨˜äº‹æ§‹é€ ã‚’çµ±åˆã—ã¦æœ€é©åŒ–ã•ã‚ŒãŸæ§‹é€ ã‚’ä½œæˆ
    """
    if len(structures_data) == 1:
        # 1ã¤ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return structures_data[0]['structure']
    
    # å…¨ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åé›†
    all_sections = []
    all_titles = []
    
    for data in structures_data:
        structure = data['structure']
        source = data['source']
        
        all_titles.append(structure.get('title', ''))
        
        for section in structure.get('sections', []):
            all_sections.append({
                'heading': section['heading'],
                'content': section.get('content', ''),
                'source': source,
                'weight': data['weight']
            })
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†æãƒ»çµ±åˆ
    integrated_sections = optimize_section_combination(all_sections)
    
    # ä»£è¡¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’é¸æŠï¼ˆæœ€ã‚‚é•·ã„ã‚‚ã®ã‹ã€æœ€åˆã®ã‚‚ã®ï¼‰
    representative_title = max(all_titles, key=len) if all_titles else ""
    
    return {
        "title": representative_title,
        "sections": integrated_sections[:5],  # æœ€å¤§5ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        "total_sections": len(integrated_sections[:5]),
        "source_count": len(structures_data),
        "sources": [data['source'] for data in structures_data]
    }

def optimize_section_combination(all_sections: list) -> list:
    """
    è¤‡æ•°è¨˜äº‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æœ€é©ã«çµ„ã¿åˆã‚ã›
    """
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é¡ä¼¼æ€§ã‚’åˆ†æ
    section_clusters = cluster_similar_sections(all_sections)
    
    # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰æœ€é©ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
    optimized_sections = []
    
    for cluster in section_clusters:
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã§æœ€ã‚‚å†…å®¹ãŒè±Šå¯Œãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
        best_section = max(cluster, key=lambda s: len(s.get('content', '')))
        
        # ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è‰¯ã„è¦ç´ ã‚‚çµ±åˆ
        enhanced_content = enhance_section_with_cluster(best_section, cluster)
        
        optimized_sections.append({
            'heading': best_section['heading'],
            'content': enhanced_content,
            'sources': [s['source'] for s in cluster]
        })
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆå†…å®¹ã®é•·ã•ç­‰ã§åˆ¤å®šï¼‰
    optimized_sections.sort(key=lambda s: len(s['content']), reverse=True)
    
    return optimized_sections

def cluster_similar_sections(sections: list) -> list:
    """
    é¡ä¼¼ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åŒ–
    """
    clusters = []
    processed = set()
    
    for i, section in enumerate(sections):
        if i in processed:
            continue
            
        cluster = [section]
        processed.add(i)
        
        # é¡ä¼¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        for j, other_section in enumerate(sections[i+1:], i+1):
            if j in processed:
                continue
                
            if are_sections_similar(section, other_section):
                cluster.append(other_section)
                processed.add(j)
        
        clusters.append(cluster)
    
    return clusters

def are_sections_similar(section1: dict, section2: dict) -> bool:
    """
    2ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®š
    """
    heading1 = section1['heading'].lower()
    heading2 = section2['heading'].lower()
    
    # ç°¡å˜ãªé¡ä¼¼åº¦åˆ¤å®šï¼ˆã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚‚å¯èƒ½ï¼‰
    common_words = set(heading1.split()) & set(heading2.split())
    
    # å…±é€šå˜èªãŒå¤šã„ã€ã¾ãŸã¯ç‰‡æ–¹ãŒä»–æ–¹ã‚’å«ã‚€å ´åˆã¯é¡ä¼¼ã¨ã¿ãªã™
    return len(common_words) >= 2 or heading1 in heading2 or heading2 in heading1

def enhance_section_with_cluster(main_section: dict, cluster: list) -> str:
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¦ç´ ã‚’ä½¿ã£ã¦å†…å®¹ã‚’æ‹¡å……
    """
    enhanced_content = main_section.get('content', '')
    
    # ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ‰ç”¨ãªè¦ç´ ã‚’æŠ½å‡º
    additional_insights = []
    for section in cluster:
        if section != main_section and section.get('content'):
            content = section['content']
            if len(content) > 50 and content not in enhanced_content:
                additional_insights.append(content[:100] + "...")
    
    if additional_insights:
        enhanced_content += " [è¿½åŠ ã®è¦–ç‚¹: " + " / ".join(additional_insights) + "]"
    
    return enhanced_content

def generate_article_from_multiple_references(prompt: str, integrated_structure: dict, num_sections: int = 5) -> dict:
    """
    è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹é€ ã«åŸºã¥ã„ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in integrated_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    source_count = integrated_structure.get('source_count', 1)
    sources = integrated_structure.get('sources', [])
    
    # å‚è€ƒè¨˜äº‹ã®æ§‹é€ ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿
    structure_text = f"çµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹æƒ…å ±ï¼ˆ{source_count}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆï¼‰:\n"
    structure_text += f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {integrated_structure.get('title', '')}\n\n"
    structure_text += "çµ±åˆã•ã‚ŒãŸè¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(integrated_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:150]}...\n"
        if section.get('sources'):
            structure_text += f"   ã‚½ãƒ¼ã‚¹: {len(section['sources'])}ã¤ã®è¨˜äº‹ã‹ã‚‰çµ±åˆ\n"
    
    structure_text += f"\nå‚è€ƒã«ã—ãŸã‚½ãƒ¼ã‚¹:\n"
    for i, source in enumerate(sources, 1):
        source_name = source.split('/')[-1] if '/' in source else source
        structure_text += f"- {source_name}\n"
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆè¤‡æ•°å‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    title_prompt = f"""
ä»¥ä¸‹ã®è¤‡æ•°ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹æˆã‚’å‚è€ƒã«ã€ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{structure_text}

è¤‡æ•°ã®è¨˜äº‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èåˆã—ã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ã§é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    
    title = generate_title_variants(title_prompt, n=1)[0]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆï¼ˆè¤‡æ•°å‚è€ƒè¨˜äº‹ã‚’è€ƒæ…®ï¼‰
    lead_msg = (
        "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
        f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’æ—¥æœ¬èªã§250æ–‡å­—ç¨‹åº¦ã€<h2>ã‚„<h3>ã¯ä½¿ã‚ãšã«æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        f"ä»¥ä¸‹ã®{source_count}ã¤ã®å‚è€ƒè¨˜äº‹ã‚’çµ±åˆã—ãŸæ§‹æˆã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n\n"
        f"{structure_text}\n\n"
        "ãƒ»è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªå°å…¥ã«ã—ã¦ãã ã•ã„\n"
        "ãƒ»3æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
        "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
        "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
        "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
        "JSONã§{\"lead\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
    )
    
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": lead_msg},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # ç« ã”ã¨ç”Ÿæˆï¼ˆçµ±åˆã•ã‚ŒãŸæ§‹é€ ã‚’æ´»ç”¨ï¼‰
    sections = []
    integrated_sections = integrated_structure.get('sections', [])
    
    for i in range(1, num_sections + 1):
        # çµ±åˆã•ã‚ŒãŸå¯¾å¿œã™ã‚‹ç« ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹
        ref_section = integrated_sections[i-1] if i-1 < len(integrated_sections) else None
        
        section_msg = (
            "ã‚ãªãŸã¯SEOå‘ã‘é•·æ–‡ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’æ—¥æœ¬èªã§340æ–‡å­—ä»¥ä¸Šã€<h2>ã§ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        )
        
        if ref_section:
            section_msg += f"å‚è€ƒã¨ãªã‚‹çµ±åˆç« ã®è¦‹å‡ºã—: ã€Œ{ref_section['heading']}ã€\n"
            if ref_section.get('content'):
                section_msg += f"çµ±åˆã•ã‚ŒãŸå†…å®¹æ¦‚è¦: {ref_section['content'][:200]}...\n"
            if ref_section.get('sources'):
                section_msg += f"ã“ã®ç« ã¯{len(ref_section['sources'])}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
            section_msg += "ä¸Šè¨˜ã®çµ±åˆã•ã‚ŒãŸæƒ…å ±ã‚’å‚è€ƒã«ã—ã¤ã¤ã€ç‹¬è‡ªæ€§ã¨åŒ…æ‹¬æ€§ã®ã‚ã‚‹å†…å®¹ã§ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
            
        section_msg += (
            "ãƒ»è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸè±Šå¯Œãªå†…å®¹ã«ã—ã¦ãã ã•ã„\n"
            "ãƒ»2æ–‡ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ã‚ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„\n"
            "ãƒ»ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§ã€å…±æ„Ÿã‚„å…·ä½“ä¾‹ã‚‚äº¤ãˆã¦ãã ã•ã„\n"
            "ãƒ»æƒ³å®šèª­è€…ï¼šä»Šã‹ã‚‰AIã‚’ä½¿ã„å§‹ã‚ã‚‹å¹…åºƒã„å¹´ä»£å±¤\n"
            "ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬çš„è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„\n"
            "JSONã§{\"section\": \"...\"}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": section_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "multiple_references": True,
        "source_count": source_count,
        "sources": sources
    }

def extract_style_features_from_sources(sources: list, content_types: list = None) -> dict:
    """
    è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’æŠ½å‡º
    """
    if content_types is None:
        content_types = []
        for source in sources:
            if source.startswith(('http://', 'https://')):
                content_types.append('url')
            elif source.endswith('.md'):
                content_types.append('markdown')
            else:
                content_types.append('html')
    
    all_style_features = []
    
    for i, (source, content_type) in enumerate(zip(sources, content_types)):
        print(f"ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ {i+1}/{len(sources)}: {source}")
        
        try:
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            if content_type == 'url':
                response = requests.get(source, timeout=30)
                response.raise_for_status()
                raw_content = response.text
                # HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                soup = BeautifulSoup(raw_content, 'html.parser')
                for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header']):
                    tag.decompose()
                content = soup.get_text('\n')
            elif content_type == 'markdown':
                with open(source, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:  # html
                with open(source, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                soup = BeautifulSoup(raw_content, 'html.parser')
                content = soup.get_text('\n')
            
            # ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’æŠ½å‡º
            features = analyze_style_features(content, source)
            if features:
                all_style_features.append(features)
                print(f"âœ… ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´æŠ½å‡ºå®Œäº†")
            
        except Exception as e:
            print(f"âŒ ã‚¹ã‚¿ã‚¤ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {source} - {e}")
    
    if not all_style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # è¤‡æ•°è¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’çµ±åˆ
    return merge_style_features(all_style_features)

def analyze_style_features(content: str, source: str) -> dict:
    """
    å˜ä¸€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’åˆ†æ
    """
    lines = content.split('\n')
    total_chars = len(content)
    total_lines = len(lines)
    
    # è¦‹å‡ºã—åˆ†æ
    h1_pattern = re.compile(r'^#\s+(.+)', re.MULTILINE)
    h2_pattern = re.compile(r'^##\s+(.+)', re.MULTILINE)
    h3_pattern = re.compile(r'^###\s+(.+)', re.MULTILINE)
    
    h1_matches = h1_pattern.findall(content)
    h2_matches = h2_pattern.findall(content)
    h3_matches = h3_pattern.findall(content)
    
    all_headings = h1_matches + h2_matches + h3_matches
    
    # çµµæ–‡å­—åˆ†æ
    emoji_pattern = re.compile(r'[ğŸš€ğŸ”¥ğŸ’¡ğŸ“ŠğŸ¯âš¡ğŸŒŸâœ¨ğŸ“ˆğŸ‰ğŸ’ªğŸ”§ğŸ“ğŸ†•ğŸ‘ğŸ”ğŸ“šğŸ¨ğŸª]')
    emoji_in_headings = sum(1 for h in all_headings if emoji_pattern.search(h))
    total_emojis = len(emoji_pattern.findall(content))
    
    # ç®‡æ¡æ›¸ãåˆ†æ
    bullet_patterns = [
        re.compile(r'^\s*[-â€¢*]\s+', re.MULTILINE),
        re.compile(r'^\s*\d+\.\s+', re.MULTILINE),
    ]
    total_bullets = sum(len(pattern.findall(content)) for pattern in bullet_patterns)
    
    # æ–‡ä½“åˆ†æ
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
    sentences = [s.strip() for s in sentences if s.strip()]
    avg_sentence_length = sum(len(s) for s in sentences) / max(1, len(sentences))
    
    # å°‚é–€ç”¨èªãƒ»è‹±èªåˆ†æ
    english_words = re.findall(r'\b[A-Za-z]{3,}\b', content)
    english_ratio = len(english_words) / max(1, len(content.split()))
    
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒ»è¡¨ã®åˆ†æ
    code_blocks = len(re.findall(r'```[\s\S]*?```', content))
    tables = len(re.findall(r'\|.+\|', content))
    
    # èªå°¾åˆ†æï¼ˆã§ã™ãƒ»ã¾ã™èª¿ vs ã§ã‚ã‚‹èª¿ï¼‰
    desu_masu = len(re.findall(r'(ã§ã™|ã¾ã™|ã§ã—ã‚‡ã†)ã€‚', content))
    de_aru = len(re.findall(r'(ã§ã‚ã‚‹|ã )ã€‚', content))
    
    word_count = len(content.split())
    
    return {
        "source": source,
        "total_chars": total_chars,
        "word_count": word_count,
        "h1_count": len(h1_matches),
        "h2_count": len(h2_matches),
        "h3_count": len(h3_matches),
        "h2_per_1000_words": (len(h2_matches) * 1000) / max(1, word_count),
        "emoji_in_headings": emoji_in_headings,
        "emoji_in_headings_ratio": emoji_in_headings / max(1, len(all_headings)),
        "total_emojis": total_emojis,
        "emoji_density": total_emojis / max(1, total_chars / 1000),
        "bullet_count": total_bullets,
        "bullet_density": total_bullets / max(1, total_lines),
        "avg_sentence_length": avg_sentence_length,
        "english_word_ratio": english_ratio,
        "code_blocks": code_blocks,
        "tables": tables,
        "desu_masu_ratio": desu_masu / max(1, desu_masu + de_aru),
        "formality_score": desu_masu / max(1, len(sentences))
    }

def merge_style_features(style_features_list: list) -> dict:
    """
    è¤‡æ•°è¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’çµ±åˆ
    """
    if len(style_features_list) == 1:
        return style_features_list[0]
    
    # æ•°å€¤ç‰¹å¾´ã®å¹³å‡ã‚’è¨ˆç®—
    numeric_features = [
        'h2_per_1000_words', 'emoji_in_headings_ratio', 'emoji_density',
        'bullet_density', 'avg_sentence_length', 'english_word_ratio',
        'desu_masu_ratio', 'formality_score'
    ]
    
    merged = {"source_count": len(style_features_list), "sources": []}
    
    for feature in numeric_features:
        values = [sf[feature] for sf in style_features_list if feature in sf]
        if values:
            merged[feature] = round(st.mean(values), 3)
    
    # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´ã®çµ±åˆ
    merged['total_code_blocks'] = sum(sf.get('code_blocks', 0) for sf in style_features_list)
    merged['total_tables'] = sum(sf.get('tables', 0) for sf in style_features_list)
    merged['sources'] = [sf.get('source', '') for sf in style_features_list]
    
    # ã‚¹ã‚¿ã‚¤ãƒ«åˆ¤å®š
    if merged.get('emoji_in_headings_ratio', 0) > 0.5:
        merged['heading_style'] = 'emoji_rich'
    elif merged.get('emoji_in_headings_ratio', 0) > 0.2:
        merged['heading_style'] = 'moderate_emoji'
    else:
        merged['heading_style'] = 'minimal_emoji'
    
    if merged.get('desu_masu_ratio', 0) > 0.7:
        merged['tone'] = 'polite'
    elif merged.get('desu_masu_ratio', 0) > 0.3:
        merged['tone'] = 'mixed'
    else:
        merged['tone'] = 'casual'
    
    if merged.get('bullet_density', 0) > 0.1:
        merged['structure_style'] = 'list_heavy'
    elif merged.get('bullet_density', 0) > 0.05:
        merged['structure_style'] = 'moderate_lists'
    else:
        merged['structure_style'] = 'paragraph_focused'
    
    return merged

def generate_style_yaml(merged_features: dict) -> str:
    """
    çµ±åˆã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‹ã‚‰YAMLã‚¬ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
    """
    style_guide = {
        "document_style": {
            "heading_frequency": f"{merged_features.get('h2_per_1000_words', 3):.1f} H2è¦‹å‡ºã— per 1000èª",
            "emoji_usage": {
                "in_headings": f"{merged_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«çµµæ–‡å­—",
                "overall_density": f"{merged_features.get('emoji_density', 0):.2f} çµµæ–‡å­— per 1000æ–‡å­—",
                "style": merged_features.get('heading_style', 'moderate_emoji')
            },
            "structure": {
                "bullet_density": f"{merged_features.get('bullet_density', 0)*100:.1f}%ã®è¡ŒãŒç®‡æ¡æ›¸ã",
                "style": merged_features.get('structure_style', 'moderate_lists'),
                "code_blocks": merged_features.get('total_code_blocks', 0) > 0,
                "tables": merged_features.get('total_tables', 0) > 0
            },
            "writing_style": {
                "tone": merged_features.get('tone', 'polite'),
                "avg_sentence_length": f"{merged_features.get('avg_sentence_length', 30):.0f}æ–‡å­—",
                "formality": merged_features.get('formality_score', 0.5),
                "english_ratio": f"{merged_features.get('english_word_ratio', 0)*100:.1f}%"
            }
        },
        "generation_rules": {
            "è¦‹å‡ºã—": "H2è¦‹å‡ºã—ã«çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨",
            "ç®‡æ¡æ›¸ã": "â€¢ ã‚’ä½¿ç”¨ã—ã€é©åº¦ãªå¯†åº¦ã§é…ç½®",
            "èªèª¿": "ã§ã™ãƒ»ã¾ã™èª¿" if merged_features.get('tone') == 'polite' else "æ··åˆèª¿",
            "æ–‡é•·": "èª­ã¿ã‚„ã™ã„é•·ã•ã«èª¿æ•´",
            "æ§‹æˆ": "è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ãæ•´ç†"
        },
        "reference_info": {
            "source_count": merged_features.get('source_count', 1),
            "analyzed_sources": merged_features.get('sources', [])
        }
    }
    
    return yaml.dump(style_guide, allow_unicode=True, default_flow_style=False, sort_keys=False)

def generate_article_with_style_guide(prompt: str, integrated_structure: dict, style_features: dict, num_sections: int = 5) -> dict:
    """
    ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in integrated_structure:
        return {"error": "å‚è€ƒè¨˜äº‹ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    if "error" in style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰YAMLã‚’ç”Ÿæˆ
    style_yaml = generate_style_yaml(style_features)
    
    source_count = integrated_structure.get('source_count', 1)
    sources = integrated_structure.get('sources', [])
    
    # æ§‹é€ æƒ…å ±
    structure_text = f"çµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹æƒ…å ±ï¼ˆ{source_count}ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆï¼‰:\n"
    structure_text += f"å‚è€ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«: {integrated_structure.get('title', '')}\n\n"
    structure_text += "çµ±åˆã•ã‚ŒãŸè¦‹å‡ºã—æ§‹æˆ:\n"
    
    for i, section in enumerate(integrated_structure.get('sections', [])[:num_sections], 1):
        structure_text += f"{i}. {section['heading']}\n"
        if section.get('content'):
            structure_text += f"   å†…å®¹ã®æ¦‚è¦: {section['content'][:150]}...\n"
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""
ã‚ãªãŸã¯è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

## ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆçµ±åˆã•ã‚ŒãŸå‚è€ƒè¨˜äº‹ã®ç‰¹å¾´ï¼‰
```yaml
{style_yaml}
```

## å‡ºåŠ›è¦ä»¶
- ä¸Šè¨˜YAMLã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’**å³å¯†ã«åæ˜ **ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
- ã™ã¹ã¦ **HTML** ã§æ›¸ãï¼ˆWordPressã«é©ã—ãŸå½¢å¼ï¼‰
- è¦‹å‡ºã—ã¯ &lt;h2&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—è¾¼ã¿ï¼‰
- è¦‹å‡ºã—é »åº¦: {style_features.get('h2_per_1000_words', 3):.1f}æœ¬/1000èª ç¨‹åº¦
- çµµæ–‡å­—ä½¿ç”¨: {style_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«é©åˆ‡ãªçµµæ–‡å­—
- ç®‡æ¡æ›¸ãã¯ &lt;ul&gt;&lt;li&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- ç®‡æ¡æ›¸ãå¯†åº¦: {style_features.get('bullet_density', 0)*100:.1f}%ç¨‹åº¦
- èªèª¿: {"ã§ã™ãƒ»ã¾ã™èª¿" if style_features.get('tone') == 'polite' else "è‡ªç„¶ãªæ··åˆèª¿"}
- æ–‡é•·: å¹³å‡{style_features.get('avg_sentence_length', 30):.0f}æ–‡å­—ç¨‹åº¦

## å‚è€ƒæ§‹é€ 
{structure_text}

ä¸Šè¨˜ã®æ§‹é€ ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’èåˆã—ã€ã€Œ{prompt}ã€ã«ã¤ã„ã¦åŒ…æ‹¬çš„ã§èª­ã¿ã‚„ã™ã„è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""

    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{prompt}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸé­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"title\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    title = json.loads(title_resp.choices[0].message.content)["title"]

    # è¨˜äº‹æœ¬æ–‡ç”Ÿæˆ
    content_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{prompt}ã€ã«ã¤ã„ã¦ã€çµ±åˆã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦2000æ–‡å­—ç¨‹åº¦ã®è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚å‚è€ƒæ§‹é€ ã‚’æ´»ç”¨ã—ã€{num_sections}ã¤ã®ä¸»è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=3000
    )
    content = content_resp.choices[0].message.content

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(prompt, content[:1000])  # è¨˜äº‹ã®æœ€åˆã®1000æ–‡å­—ã‚’å‚è€ƒã«
    
    # FAQã‚’è¨˜äº‹ã«è¿½åŠ 
    content += "\n" + faq_section
    
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "multiple_references": True,
        "style_guided": True,
        "source_count": source_count,
        "sources": sources,
        "style_features": style_features,
        "style_yaml": style_yaml
    }

def generate_keyword_article_with_style(keyword: str, style_features: dict, num_sections: int = 5) -> dict:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã‚’é©ç”¨ã—ãŸè¨˜äº‹ã‚’ç”Ÿæˆ
    """
    if "error" in style_features:
        return {"error": "ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰YAMLã‚’ç”Ÿæˆ
    style_yaml = generate_style_yaml(style_features)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä»˜ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""
ã‚ãªãŸã¯è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

## ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆå‚è€ƒè¨˜äº‹ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ï¼‰
```yaml
{style_yaml}
```

## å‡ºåŠ›è¦ä»¶
- ä¸Šè¨˜YAMLã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’**å³å¯†ã«åæ˜ **ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ
- ã™ã¹ã¦ **HTML** ã§æ›¸ãï¼ˆWordPressã«é©ã—ãŸå½¢å¼ï¼‰
- è¦‹å‡ºã—ã¯ &lt;h2&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ï¼ˆçµµæ–‡å­—è¾¼ã¿ï¼‰
- è¦‹å‡ºã—é »åº¦: {style_features.get('h2_per_1000_words', 3):.1f}æœ¬/1000èª ç¨‹åº¦
- çµµæ–‡å­—ä½¿ç”¨: {style_features.get('emoji_in_headings_ratio', 0)*100:.0f}%ã®è¦‹å‡ºã—ã«é©åˆ‡ãªçµµæ–‡å­—
- ç®‡æ¡æ›¸ãã¯ &lt;ul&gt;&lt;li&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨
- ç®‡æ¡æ›¸ãå¯†åº¦: {style_features.get('bullet_density', 0)*100:.1f}%ç¨‹åº¦
- **ãƒªãƒƒãƒãªè¡¨ã‚’ç©æ¥µæ´»ç”¨**: æ¯”è¼ƒãƒ»æ‰‹é †ãƒ»ãƒ‡ãƒ¼ã‚¿ã¯&lt;table&gt;&lt;tr&gt;&lt;td&gt;ã‚¿ã‚°ã§æ§‹é€ åŒ–
- **å¯¾è©±å½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹**: å®Ÿéš›ã®ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆä¾‹ï¼šã€Œã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ï¼‰
- èªèª¿: {"ã§ã™ãƒ»ã¾ã™èª¿" if style_features.get('tone') == 'polite' else "è‡ªç„¶ãªæ··åˆèª¿"}
- æ–‡é•·: å¹³å‡{style_features.get('avg_sentence_length', 30):.0f}æ–‡å­—ç¨‹åº¦
- **æœ¬æ–‡çµµæ–‡å­—**: æ–‡ç« ã®ç´„20%ã«é©åˆ‡ãªçµµæ–‡å­—ã‚’è‡ªç„¶ã«é…ç½®ï¼ˆæ„Ÿæƒ…è¡¨ç¾ãƒ»å¼·èª¿ãƒ»è¦–è¦šçš„ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼‰

## è¨˜äº‹ç”ŸæˆæŒ‡é‡ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆãƒªãƒƒãƒã‚¹ã‚¿ã‚¤ãƒ«ï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœã€ã®3åˆ—æ§‹æˆã§ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä¼šè©±å½¢å¼ã§è¡¨ç¾ï¼ˆã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€ï¼‰
3. **FAQå½¢å¼**: Q&Aå½¢å¼ã§èª­ã¿ã‚„ã™ãæƒ…å ±ã‚’æ•´ç†
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ
5. **å…·ä½“çš„ãªäº‹ä¾‹**: å®Ÿéš›ã«ä½¿ãˆã‚‹ä¾‹ã‚’è±Šå¯Œã«æä¾›

## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è¨˜äº‹ç”Ÿæˆ
ã€Œ{keyword}ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ†ãƒ¼ãƒã«ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸè¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
- SEOã‚’æ„è­˜ã—ãŸæ§‹æˆ
- æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å†…å®¹
- å‚è€ƒè¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å¿ å®Ÿã«å†ç¾
- è¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãƒ»å…·ä½“ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
"""

    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    title_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸé­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"title\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=200,
        response_format={"type": "json_object"}
    )
    title = json.loads(title_resp.choices[0].message.content)["title"]

    # ãƒªãƒ¼ãƒ‰æ–‡ç”Ÿæˆ
    lead_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸãƒªãƒ¼ãƒ‰æ–‡ï¼ˆå°å…¥éƒ¨ï¼‰ã‚’250æ–‡å­—ç¨‹åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚JSONã§{{\"lead\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    lead_text = json.loads(lead_resp.choices[0].message.content)["lead"]

    # å®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    try:
        practical_examples = generate_practical_examples(keyword)
        print(f"âœ… å®Ÿè·µä¾‹ç”Ÿæˆå®Œäº†: {len(practical_examples)}æ–‡å­—")
    except Exception as e:
        print(f"âš ï¸ å®Ÿè·µä¾‹ç”Ÿæˆå¤±æ•—: {e}")
        practical_examples = ""

    # ç« ã”ã¨ç”Ÿæˆ
    sections = []
    for i in range(1, num_sections + 1):
        # 3ç« ç›®ã«å®Ÿè·µä¾‹ã‚’æŒ¿å…¥
        if i == 3 and practical_examples:
            user_content = f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ¨ çµµæ–‡å­—ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼šæœ¬æ–‡ã®ç´„20%ã®æ–‡ã«è‡ªç„¶ã«çµµæ–‡å­—ã‚’é…ç½®ï¼ˆğŸ˜Š âœ¨ ğŸ¯ ğŸ’¡ ğŸ“ ğŸš€ãªã©ï¼‰\n\nä»¥ä¸‹ã®å®Ÿè·µä¾‹ã‚’æ´»ç”¨ã—ã¦å®Ÿç”¨çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚\n\nå®Ÿè·µä¾‹:\n{practical_examples}\n\nJSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        else:
            user_content = f"ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã®è¨˜äº‹ã®ç¬¬{i}ç« ã‚’ã€ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦340æ–‡å­—ä»¥ä¸Šã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¦‹å‡ºã—ã¯&lt;h2&gt;&lt;/h2&gt;ã‚¿ã‚°ã§å›²ã‚“ã§ãã ã•ã„ã€‚\n\nğŸ¨ çµµæ–‡å­—ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼šæœ¬æ–‡ã®ç´„20%ã®æ–‡ã«è‡ªç„¶ã«çµµæ–‡å­—ã‚’é…ç½®ï¼ˆğŸ˜Š âœ¨ ğŸ¯ ğŸ’¡ ğŸ“ ğŸš€ãªã©ï¼‰\n\nå¯èƒ½ãªé™ã‚Šè¡¨ãƒ»å…·ä½“ä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’å«ã‚ã¦å®Ÿè·µçš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚JSONã§{{\"section\": \"...\"}}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        
        section_resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=800,
            response_format={"type": "json_object"}
        )
        section_text = json.loads(section_resp.choices[0].message.content)["section"]
        sections.append(section_text)

    # FAQç”Ÿæˆ
    faq_section = generate_faq_section(keyword, lead_text + "\n".join(sections[:2]))  # æœ€åˆã®2ç« ã‚’å‚è€ƒã«
    
    # çµåˆ
    content = lead_text + "\n" + "\n".join(sections) + "\n" + faq_section
    
    return {
        "title": title,
        "content": content,
        "reference_used": True,
        "style_guided": True,
        "keyword_based": True,
        "keyword": keyword,
        "style_features": style_features,
        "style_yaml": style_yaml
    }

def generate_practical_examples(keyword: str) -> str:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¿œã˜ãŸå®Ÿè·µçš„ãªä¾‹ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆ
    """
    example_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system", 
                "content": """
ã‚ãªãŸã¯åˆå¿ƒè€…ã«ã‚„ã•ã—ã„å®Ÿè·µä¾‹ãƒ»å¯¾è©±ä¾‹ã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¿œã˜ã¦ã€èª­è€…ãŒå®Ÿéš›ã«è©¦ã›ã‚‹å…·ä½“çš„ãªä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«æº–æ‹ ï¼‰
ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€HTMLã§è¿”ã—ã¦ãã ã•ã„ï¼š
1. **æ¯”è¼ƒè¡¨ï¼ˆ3åˆ—æ§‹æˆï¼‰**: ã€ŒNGä¾‹ã€ã€Œæ”¹å–„ä¾‹ã€ã€ŒåŠ¹æœãƒ»ãƒã‚¤ãƒ³ãƒˆã€ã®æ§‹æˆã§è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã
2. **å¯¾è©±å½¢å¼ã®ä¾‹**: ã€ŒChatGPTã«ã€ã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã¨èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€å½¢å¼
3. **FAQå½¢å¼**: ã€ŒQ: ã‚ˆãã‚ã‚‹è³ªå•ã€ã€ŒA: ã‚ã‹ã‚Šã‚„ã™ã„å›ç­”ã€å½¢å¼
4. **æ®µéšçš„ãªæ‰‹é †**: åˆå¿ƒè€…ã§ã‚‚è¿·ã‚ãªã„1-2-3ã‚¹ãƒ†ãƒƒãƒ—æ§‹æˆ

## é‡è¦ãªæŒ‡é‡
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã¯å¿…ãšå¯¾è©±å½¢å¼ã§è¡¨ç¾ï¼ˆã‚³ãƒ¼ãƒ‰é¢¨ã§ã¯ãªãã€è‡ªç„¶ãªä¼šè©±ï¼‰
- è¡¨ã¯æƒ…å ±ãŒæ•´ç†ã•ã‚Œã€åˆå¿ƒè€…ãŒä¸€ç›®ã§ç†è§£ã§ãã‚‹ã‚¹ã‚¿ã‚¤ãƒ«
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãšã€ã‚„ã•ã—ã„è¨€è‘‰ã§èª¬æ˜

JSONã§{"examples": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹å®Ÿè·µçš„ãªä¾‹ãƒ»æ¯”è¼ƒè¡¨ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"}
        ],
        temperature=0.7,
        max_tokens=1000,
        response_format={"type": "json_object"}
    )
    
    return json.loads(example_resp.choices[0].message.content)["examples"]

def generate_faq_section(prompt: str, article_content: str) -> str:
    """
    è¨˜äº‹ã®ãƒ†ãƒ¼ãƒã«é–¢é€£ã—ãŸFAQ 3ã¤ã‚’ç”Ÿæˆï¼ˆAI-GENEã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    """
    faq_resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """
ã‚ãªãŸã¯èª­è€…ã®ç–‘å•ã‚’å…ˆèª­ã¿ã™ã‚‹FAQå°‚é–€ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¨˜äº‹ãƒ†ãƒ¼ãƒã¨å†…å®¹ã‹ã‚‰ã€èª­è€…ãŒå¿…ãšæŠ±ãè³ªå•ã‚’3ã¤é¸ã‚“ã§ã€Q&Aå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›è¦ä»¶
- HTMLã§&lt;h3&gt;ã‚¿ã‚°ã‚’ä½¿ç”¨ã—ã¦FAQã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
- å„è³ªå•ã¯&lt;h4&gt;ã‚¿ã‚°ã§ã€ŒQ: è³ªå•å†…å®¹ã€å½¢å¼
- å„å›ç­”ã¯&lt;p&gt;ã‚¿ã‚°ã§ã€ŒA: å›ç­”å†…å®¹ã€å½¢å¼  
- çµµæ–‡å­—ã‚’åŠ¹æœçš„ã«æ´»ç”¨ï¼ˆè³ªå•ã«â“ã€å›ç­”ã«âœ…ãªã©ï¼‰
- åˆå¿ƒè€…ã§ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§å›ç­”
- å®Ÿè·µçš„ã§å…·ä½“çš„ãªå†…å®¹

## FAQé¸å®šåŸºæº–
1. åˆå¿ƒè€…ãŒå¿…ãšç–‘å•ã«æ€ã†ã“ã¨
2. è¨˜äº‹ã‚’èª­ã‚“ã å¾Œã®æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
3. ã‚ˆãã‚ã‚‹èª¤è§£ã‚„æ³¨æ„ç‚¹

JSONã§{"faq": "..."}ã®å½¢ã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
            },
            {"role": "user", "content": f"è¨˜äº‹ãƒ†ãƒ¼ãƒ: {prompt}\n\nè¨˜äº‹å†…å®¹ã®è¦ç´„: {article_content[:500]}..."}
        ],
        temperature=0.7,
        max_tokens=800,
        response_format={"type": "json_object"}
    )
    return json.loads(faq_resp.choices[0].message.content)["faq"]

if __name__ == "__main__":
    keyword = get_next_keyword(col=0)  # Aåˆ—ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
    prompt = f"{keyword}ã«ã¤ã„ã¦ã®è¨˜äº‹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚SEOã‚’æ„è­˜ã—ã¦ã€æ¤œç´¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"
    print("â˜…ä»Šå›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:", prompt)
    print(generate_title_variants(prompt, n=3))
    article = generate_article_html(prompt)
    print(article)

